{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "listed-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1419,  0.0333, -0.5132,  1.1087],\n",
       "        [-1.4777, -0.7418, -1.0676, -0.6446]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(0, 1, (2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "martial-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "above-costs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.Tensor([2.4, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "olympic-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_train_data(w, b, samples_num):\n",
    "    \"\"\"生成随机训练数据\"\"\"\n",
    "    x = torch.normal(0, 1, (samples_num, len(w)))\n",
    "    y = linear_regression(w, b, x)\n",
    "    y += torch.normal(0, 0.1, y.shape)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def squared_loss(y, y_hat):\n",
    "    return 0.5 * (y - y_hat.reshape(y.shape)) ** 2\n",
    "\n",
    "\n",
    "def linear_regression(w, b, x):\n",
    "    y = torch.matmul(x, w) + b\n",
    "    return y\n",
    "\n",
    "def sgd(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "            \n",
    "def data_iter(x, y, batch_size):\n",
    "    indices = list(range(len(y)))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, len(y), batch_size):\n",
    "        sample_index = indices[i:min(i + batch_size, len(y))]\n",
    "        yield x[sample_index], y[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "private-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.Tensor([2.4, 3])\n",
    "true_b = 4\n",
    "samples_num = 200\n",
    "train_x, train_y = generate_train_data(true_w, true_b, samples_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "private-consultancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "greek-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '训练样本')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10,5), dpi=100)\n",
    "plt.scatter(train_x[:, 0].detach().numpy(), train_y.detach().numpy())\n",
    "plt.title('训练样本')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "other-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(mean=0, std=1, size=(2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "joined-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5438],\n",
       "        [-2.1507]], requires_grad=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "equivalent-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "heated-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , squared loss: 4.142693042755127\n",
      "epoch: 1 , squared loss: 0.9017737507820129\n",
      "epoch: 2 , squared loss: 0.41906505823135376\n",
      "epoch: 3 , squared loss: 0.3290206789970398\n",
      "epoch: 4 , squared loss: 0.040176812559366226\n",
      "epoch: 5 , squared loss: 0.03281446173787117\n",
      "epoch: 6 , squared loss: 0.00747916754335165\n",
      "epoch: 7 , squared loss: 0.005919931922107935\n",
      "epoch: 8 , squared loss: 0.007160825189203024\n",
      "epoch: 9 , squared loss: 0.0038021665532141924\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "batch_size = 10\n",
    "epoch = 10\n",
    "\n",
    "for ep in range(epoch):\n",
    "    for x, y in data_iter(train_x, train_y, batch_size):\n",
    "        y_hat = linear_regression(w, b, x)\n",
    "        loss = squared_loss(y, y_hat)\n",
    "        loss.sum().backward()\n",
    "        sgd([w, b], lr, batch_size)\n",
    "    with torch.no_grad():\n",
    "        y_hat = linear_regression(w, b, x)\n",
    "        loss = squared_loss(y, y_hat)\n",
    "    print('epoch: {} , squared loss: {}'.format(ep, loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "quick-happiness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3991],\n",
       "        [2.9853]], requires_grad=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "horizontal-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9831], requires_grad=True)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "entertaining-institution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0009],\n",
       "        [0.0147]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w.reshape(2, 1) - w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "least-carnival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0169], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-checklist",
   "metadata": {},
   "source": [
    "## Pytorch简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "chinese-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "found-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "complex-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 1)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "gothic-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "lonely-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.Tensor([2.4, 3])\n",
    "true_b = 4\n",
    "samples_num = 200\n",
    "train_x, train_y = generate_train_data(true_w, true_b, samples_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "representative-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "missing-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "def data_iter(x, y, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(x, y)\n",
    "    dataset = data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "elder-workplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 1)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "funny-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-11.0620,  -9.2034]])\n",
      "tensor([[-2.0907, -2.5534]])\n",
      "tensor([[-5.6751, -0.2993]])\n",
      "tensor([[-8.6254, -3.6669]])\n",
      "tensor([[-5.1859, -3.6522]])\n",
      "tensor([[-1.2703,  0.7383]])\n",
      "tensor([[-2.0521,  1.4963]])\n",
      "tensor([[-2.4410, -5.3908]])\n",
      "tensor([[-7.2600, -1.4032]])\n",
      "tensor([[-5.5400, -4.3227]])\n",
      "tensor([[-4.6589, -3.8994]])\n",
      "tensor([[-4.3860, -4.6178]])\n",
      "tensor([[-2.3625, -8.1048]])\n",
      "tensor([[-5.6433, -2.9961]])\n",
      "tensor([[-0.8740, -0.1657]])\n",
      "tensor([[-4.9462, -6.6822]])\n",
      "tensor([[ 0.3488, -2.2358]])\n",
      "tensor([[-3.1947, -3.5473]])\n",
      "tensor([[-2.7347, -1.2232]])\n",
      "tensor([[-4.5431, -1.2125]])\n",
      "epoch: 0 , loss: 11.102617263793945\n",
      "tensor([[-3.2525, -2.4622]])\n",
      "tensor([[-2.2598, -2.8199]])\n",
      "tensor([[-1.7740, -3.8303]])\n",
      "tensor([[-2.4689,  0.1182]])\n",
      "tensor([[-4.0084, -0.8292]])\n",
      "tensor([[-2.1290, -2.0697]])\n",
      "tensor([[-2.2272, -0.5062]])\n",
      "tensor([[-2.8289, -1.6309]])\n",
      "tensor([[-2.7576, -2.6453]])\n",
      "tensor([[-3.3685, -2.5851]])\n",
      "tensor([[-3.6229, -2.5262]])\n",
      "tensor([[-2.5089, -1.3847]])\n",
      "tensor([[-1.6959, -3.4085]])\n",
      "tensor([[-4.2228, -2.8825]])\n",
      "tensor([[-2.9007, -0.3776]])\n",
      "tensor([[-3.9646, -0.5105]])\n",
      "tensor([[ 0.9817, -1.7889]])\n",
      "tensor([[-2.6905, -1.4723]])\n",
      "tensor([[-3.7105, -2.4656]])\n",
      "tensor([[-2.8823, -4.6911]])\n",
      "epoch: 1 , loss: 8.01722240447998\n",
      "tensor([[-2.1793, -3.6066]])\n",
      "tensor([[-1.5334, -1.7862]])\n",
      "tensor([[-2.0033, -1.9024]])\n",
      "tensor([[-2.3328, -1.5112]])\n",
      "tensor([[-3.5044, -1.1064]])\n",
      "tensor([[-2.6472,  0.0414]])\n",
      "tensor([[-0.5707, -2.6803]])\n",
      "tensor([[-2.7979, -1.7725]])\n",
      "tensor([[-3.2946, -2.1347]])\n",
      "tensor([[ 0.0647, -0.8463]])\n",
      "tensor([[-3.3107, -1.9751]])\n",
      "tensor([[-0.2189,  0.4364]])\n",
      "tensor([[-0.5207, -0.1516]])\n",
      "tensor([[-0.9178, -0.0949]])\n",
      "tensor([[-0.7456, -2.2144]])\n",
      "tensor([[-1.3026, -0.6890]])\n",
      "tensor([[-1.2465, -1.6096]])\n",
      "tensor([[-1.0708,  0.0869]])\n",
      "tensor([[-2.8949, -1.4372]])\n",
      "tensor([[-1.8768, -1.5012]])\n",
      "epoch: 2 , loss: 2.7626125812530518\n",
      "tensor([[-0.8666,  0.3030]])\n",
      "tensor([[-2.1852, -2.0023]])\n",
      "tensor([[-2.1889, -0.9540]])\n",
      "tensor([[-1.3868,  0.1228]])\n",
      "tensor([[-1.7646, -1.9517]])\n",
      "tensor([[-0.4359, -1.3844]])\n",
      "tensor([[-2.0942, -0.6910]])\n",
      "tensor([[ 0.1428, -0.5581]])\n",
      "tensor([[-2.2292, -1.5152]])\n",
      "tensor([[-0.6380,  0.2267]])\n",
      "tensor([[-1.5191, -0.9488]])\n",
      "tensor([[-1.7523, -1.7549]])\n",
      "tensor([[ 0.2082, -1.2111]])\n",
      "tensor([[-1.0466, -0.0778]])\n",
      "tensor([[-0.6467, -1.5314]])\n",
      "tensor([[-0.3076, -0.2902]])\n",
      "tensor([[-0.8180, -0.3027]])\n",
      "tensor([[-1.0170, -2.1648]])\n",
      "tensor([[-1.1789, -0.5914]])\n",
      "tensor([[-0.7157,  0.1283]])\n",
      "epoch: 3 , loss: 0.8586421012878418\n",
      "tensor([[-0.8698, -0.6065]])\n",
      "tensor([[-0.2699, -0.5984]])\n",
      "tensor([[-0.1580, -0.3150]])\n",
      "tensor([[-1.1972,  0.3356]])\n",
      "tensor([[-1.9546, -1.5511]])\n",
      "tensor([[-0.6345,  0.0430]])\n",
      "tensor([[-0.7328, -0.9858]])\n",
      "tensor([[-0.8507, -0.2968]])\n",
      "tensor([[-0.1260, -0.1775]])\n",
      "tensor([[-1.8315, -1.0107]])\n",
      "tensor([[-0.3993,  0.0590]])\n",
      "tensor([[-1.2795, -1.2922]])\n",
      "tensor([[-0.5376, -0.5229]])\n",
      "tensor([[-1.7446, -0.7385]])\n",
      "tensor([[-0.4870, -0.5834]])\n",
      "tensor([[-4.6643e-01, -4.4744e-04]])\n",
      "tensor([[-0.0395, -0.5149]])\n",
      "tensor([[-0.1958, -0.5436]])\n",
      "tensor([[-0.7328, -0.8705]])\n",
      "tensor([[-0.1145, -1.0498]])\n",
      "epoch: 4 , loss: 0.5204260349273682\n",
      "tensor([[-0.4763, -0.7904]])\n",
      "tensor([[ 0.2258, -1.0844]])\n",
      "tensor([[-0.5206,  0.0444]])\n",
      "tensor([[-0.5705, -0.7282]])\n",
      "tensor([[-0.2011, -0.4077]])\n",
      "tensor([[-1.6804, -0.4643]])\n",
      "tensor([[-0.3202, -0.1996]])\n",
      "tensor([[-0.3196, -0.0202]])\n",
      "tensor([[-0.1804,  0.0557]])\n",
      "tensor([[-0.0542, -0.2946]])\n",
      "tensor([[-1.0306, -0.8331]])\n",
      "tensor([[-0.1413, -0.2091]])\n",
      "tensor([[-0.6944, -0.7871]])\n",
      "tensor([[-0.7094, -0.1900]])\n",
      "tensor([[-0.5532, -0.4211]])\n",
      "tensor([[-0.8738, -0.0840]])\n",
      "tensor([[-0.7236, -0.3695]])\n",
      "tensor([[ 0.2217, -0.5280]])\n",
      "tensor([[-0.3811,  0.0487]])\n",
      "tensor([[-0.4894, -0.0871]])\n",
      "epoch: 5 , loss: 0.20198914408683777\n",
      "tensor([[-0.1153, -0.4719]])\n",
      "tensor([[-0.1383,  0.0737]])\n",
      "tensor([[-0.2162,  0.0260]])\n",
      "tensor([[-0.3564, -0.5018]])\n",
      "tensor([[-0.1360, -0.3424]])\n",
      "tensor([[-0.3020, -0.0464]])\n",
      "tensor([[-0.5301, -0.0319]])\n",
      "tensor([[-0.4128, -0.5549]])\n",
      "tensor([[-0.5941, -0.3567]])\n",
      "tensor([[ 0.0672, -0.3153]])\n",
      "tensor([[-0.8755, -0.0586]])\n",
      "tensor([[-0.1109, -0.0072]])\n",
      "tensor([[-0.5867, -0.4235]])\n",
      "tensor([[-0.6059, -0.3346]])\n",
      "tensor([[-0.1970, -0.2370]])\n",
      "tensor([[-0.0498,  0.2308]])\n",
      "tensor([[-0.2505, -0.7375]])\n",
      "tensor([[0.0753, 0.0853]])\n",
      "tensor([[-0.4445, -0.3818]])\n",
      "tensor([[-0.3502, -0.3824]])\n",
      "epoch: 6 , loss: 0.11610165983438492\n",
      "tensor([[-0.0489, -0.2123]])\n",
      "tensor([[-0.1627, -0.1805]])\n",
      "tensor([[-0.2207, -0.1349]])\n",
      "tensor([[-0.2146, -0.0335]])\n",
      "tensor([[-0.0327, -0.1369]])\n",
      "tensor([[-0.3937,  0.0008]])\n",
      "tensor([[-0.2138,  0.0859]])\n",
      "tensor([[ 0.0159, -0.2499]])\n",
      "tensor([[-0.0375, -0.0327]])\n",
      "tensor([[-0.2088, -0.2154]])\n",
      "tensor([[-0.0763, -0.3107]])\n",
      "tensor([[-0.3348, -0.1836]])\n",
      "tensor([[-0.5462, -0.2633]])\n",
      "tensor([[-0.5086, -0.1679]])\n",
      "tensor([[-0.2062, -0.3963]])\n",
      "tensor([[-0.1434, -0.2415]])\n",
      "tensor([[-0.0486, -0.1366]])\n",
      "tensor([[-0.2402, -0.1693]])\n",
      "tensor([[-0.2930,  0.0103]])\n",
      "tensor([[-0.0723, -0.1292]])\n",
      "epoch: 7 , loss: 0.05014047771692276\n",
      "tensor([[-0.2138, -0.4078]])\n",
      "tensor([[-0.1721, -0.0211]])\n",
      "tensor([[-0.2865, -0.1151]])\n",
      "tensor([[-0.1454, -0.1983]])\n",
      "tensor([[-0.0643, -0.2285]])\n",
      "tensor([[-0.1322, -0.0210]])\n",
      "tensor([[-0.0061, -0.0178]])\n",
      "tensor([[-0.0272, -0.1563]])\n",
      "tensor([[-0.3955, -0.2855]])\n",
      "tensor([[-0.1142,  0.0640]])\n",
      "tensor([[-0.1465, -0.1075]])\n",
      "tensor([[-0.0845, -0.1828]])\n",
      "tensor([[ 0.0162, -0.0215]])\n",
      "tensor([[-0.2350, -0.1830]])\n",
      "tensor([[-0.0824, -0.1472]])\n",
      "tensor([[-0.1701,  0.1119]])\n",
      "tensor([[-0.1557, -0.1552]])\n",
      "tensor([[ 0.1432, -0.1623]])\n",
      "tensor([[-0.1157,  0.0220]])\n",
      "tensor([[-0.1868,  0.2010]])\n",
      "epoch: 8 , loss: 0.03606630861759186\n",
      "tensor([[-0.0715, -0.0760]])\n",
      "tensor([[-0.0230, -0.0909]])\n",
      "tensor([[-0.1793, -0.2734]])\n",
      "tensor([[-0.1079,  0.0671]])\n",
      "tensor([[ 0.0796, -0.0595]])\n",
      "tensor([[-0.0674, -0.0743]])\n",
      "tensor([[-0.1287, -0.0921]])\n",
      "tensor([[ 0.0648, -0.0888]])\n",
      "tensor([[-0.1574, -0.2407]])\n",
      "tensor([[0.0331, 0.0809]])\n",
      "tensor([[-0.2580,  0.0550]])\n",
      "tensor([[-0.0532,  0.0072]])\n",
      "tensor([[-0.1876, -0.0517]])\n",
      "tensor([[0.0700, 0.0485]])\n",
      "tensor([[-0.1204, -0.0478]])\n",
      "tensor([[-0.1294, -0.1641]])\n",
      "tensor([[-0.1507, -0.1314]])\n",
      "tensor([[-0.0911, -0.0448]])\n",
      "tensor([[-0.2232, -0.1442]])\n",
      "tensor([[-0.0198,  0.0017]])\n",
      "epoch: 9 , loss: 0.019993670284748077\n",
      "tensor([[-0.0806, -0.0550]])\n",
      "tensor([[-0.1037, -0.0256]])\n",
      "tensor([[-0.1093, -0.0420]])\n",
      "tensor([[-0.0661,  0.0627]])\n",
      "tensor([[-0.0635, -0.0855]])\n",
      "tensor([[-0.0308, -0.0109]])\n",
      "tensor([[ 0.0310, -0.0943]])\n",
      "tensor([[-0.0769, -0.0876]])\n",
      "tensor([[ 0.0947, -0.0951]])\n",
      "tensor([[ 0.0580, -0.1418]])\n",
      "tensor([[ 0.1249, -0.0696]])\n",
      "tensor([[-0.0796,  0.0789]])\n",
      "tensor([[-0.1687, -0.0310]])\n",
      "tensor([[-0.0327, -0.0597]])\n",
      "tensor([[-0.1587,  0.0170]])\n",
      "tensor([[-0.1698, -0.1807]])\n",
      "tensor([[-0.0857, -0.0840]])\n",
      "tensor([[-0.0130,  0.0163]])\n",
      "tensor([[0.0114, 0.0057]])\n",
      "tensor([[-0.1142,  0.0098]])\n",
      "epoch: 10 , loss: 0.0162406787276268\n",
      "tensor([[-0.0313, -0.0143]])\n",
      "tensor([[ 0.0517, -0.0367]])\n",
      "tensor([[-0.3443, -0.1107]])\n",
      "tensor([[-0.0147,  0.1036]])\n",
      "tensor([[ 0.0388, -0.0477]])\n",
      "tensor([[0.1468, 0.0875]])\n",
      "tensor([[ 0.0067, -0.0550]])\n",
      "tensor([[ 0.0071, -0.0872]])\n",
      "tensor([[-0.0746, -0.0556]])\n",
      "tensor([[-0.0221,  0.0112]])\n",
      "tensor([[-0.0590, -0.0758]])\n",
      "tensor([[-0.0079, -0.1872]])\n",
      "tensor([[-0.0460, -0.1212]])\n",
      "tensor([[-0.0739,  0.0489]])\n",
      "tensor([[-0.1081,  0.0237]])\n",
      "tensor([[-0.0003, -0.0688]])\n",
      "tensor([[-0.2266, -0.0338]])\n",
      "tensor([[0.0011, 0.0748]])\n",
      "tensor([[ 0.0319, -0.0921]])\n",
      "tensor([[-0.0270,  0.0465]])\n",
      "epoch: 11 , loss: 0.013683507218956947\n",
      "tensor([[-0.1107, -0.1522]])\n",
      "tensor([[ 0.1651, -0.0112]])\n",
      "tensor([[0.0154, 0.0308]])\n",
      "tensor([[0.0659, 0.0168]])\n",
      "tensor([[ 0.0045, -0.0894]])\n",
      "tensor([[-0.0228, -0.0256]])\n",
      "tensor([[-0.0041, -0.1250]])\n",
      "tensor([[-0.0184,  0.0213]])\n",
      "tensor([[-0.2601,  0.1332]])\n",
      "tensor([[-0.0005, -0.0186]])\n",
      "tensor([[ 0.0397, -0.0002]])\n",
      "tensor([[-0.0447, -0.0289]])\n",
      "tensor([[-0.0455,  0.0977]])\n",
      "tensor([[-0.1070, -0.0834]])\n",
      "tensor([[-0.0308, -0.1126]])\n",
      "tensor([[-0.0517,  0.0079]])\n",
      "tensor([[-0.0052,  0.0019]])\n",
      "tensor([[-0.1136, -0.0937]])\n",
      "tensor([[-0.0161,  0.1302]])\n",
      "tensor([[ 0.0444, -0.0478]])\n",
      "epoch: 12 , loss: 0.022585967555642128\n",
      "tensor([[0.0110, 0.0587]])\n",
      "tensor([[ 0.0156, -0.0082]])\n",
      "tensor([[-0.0070,  0.0151]])\n",
      "tensor([[ 0.0486, -0.0085]])\n",
      "tensor([[-0.0782,  0.1442]])\n",
      "tensor([[ 0.0116, -0.0359]])\n",
      "tensor([[ 0.0140, -0.0393]])\n",
      "tensor([[-0.1324, -0.0315]])\n",
      "tensor([[-0.0148, -0.0930]])\n",
      "tensor([[ 0.0147, -0.0020]])\n",
      "tensor([[-0.0058,  0.0031]])\n",
      "tensor([[ 0.0362, -0.0880]])\n",
      "tensor([[ 0.0944, -0.1334]])\n",
      "tensor([[ 0.0284, -0.0007]])\n",
      "tensor([[ 0.0102, -0.0543]])\n",
      "tensor([[-0.0052, -0.0398]])\n",
      "tensor([[-0.0310, -0.0044]])\n",
      "tensor([[-0.0345,  0.0153]])\n",
      "tensor([[-0.2084,  0.1054]])\n",
      "tensor([[-0.1143, -0.0912]])\n",
      "epoch: 13 , loss: 0.010019439272582531\n",
      "tensor([[-0.0476,  0.0200]])\n",
      "tensor([[ 0.1221, -0.0346]])\n",
      "tensor([[-0.0168, -0.0224]])\n",
      "tensor([[-0.0481, -0.0897]])\n",
      "tensor([[ 0.0205, -0.0490]])\n",
      "tensor([[-0.0016,  0.0256]])\n",
      "tensor([[-0.0095,  0.0895]])\n",
      "tensor([[-0.0265,  0.0013]])\n",
      "tensor([[-0.2116, -0.0064]])\n",
      "tensor([[-0.0169, -0.1859]])\n",
      "tensor([[ 0.0062, -0.0013]])\n",
      "tensor([[-0.0809,  0.1716]])\n",
      "tensor([[ 0.0568, -0.0572]])\n",
      "tensor([[ 0.0341, -0.0592]])\n",
      "tensor([[ 0.0467, -0.0269]])\n",
      "tensor([[ 0.0202, -0.1038]])\n",
      "tensor([[-0.0249,  0.0728]])\n",
      "tensor([[-0.0393,  0.1560]])\n",
      "tensor([[ 0.0949, -0.0113]])\n",
      "tensor([[-0.0363, -0.0127]])\n",
      "epoch: 14 , loss: 0.0061327083967626095\n",
      "tensor([[-0.0178,  0.0010]])\n",
      "tensor([[-0.0637, -0.0245]])\n",
      "tensor([[-0.0985, -0.0984]])\n",
      "tensor([[ 0.0286, -0.0144]])\n",
      "tensor([[-0.0835, -0.1197]])\n",
      "tensor([[ 0.0893, -0.0123]])\n",
      "tensor([[0.0394, 0.0296]])\n",
      "tensor([[0.0428, 0.0170]])\n",
      "tensor([[ 0.0533, -0.0705]])\n",
      "tensor([[-0.0485, -0.0060]])\n",
      "tensor([[ 0.0188, -0.0187]])\n",
      "tensor([[-0.0633,  0.0380]])\n",
      "tensor([[ 0.0474, -0.0185]])\n",
      "tensor([[-0.1318, -0.0655]])\n",
      "tensor([[ 0.0226, -0.0674]])\n",
      "tensor([[-0.0407,  0.1852]])\n",
      "tensor([[-0.0515,  0.1080]])\n",
      "tensor([[0.0274, 0.1548]])\n",
      "tensor([[ 0.0739, -0.0082]])\n",
      "tensor([[ 0.0729, -0.0541]])\n",
      "epoch: 15 , loss: 0.0139406006783247\n",
      "tensor([[ 0.0529, -0.0132]])\n",
      "tensor([[-0.1252,  0.0924]])\n",
      "tensor([[0.0032, 0.0403]])\n",
      "tensor([[-0.0104,  0.1059]])\n",
      "tensor([[-0.0263,  0.0276]])\n",
      "tensor([[-0.1990,  0.0265]])\n",
      "tensor([[-0.0446, -0.1302]])\n",
      "tensor([[ 0.0339, -0.1171]])\n",
      "tensor([[-0.0523, -0.0911]])\n",
      "tensor([[0.1511, 0.0549]])\n",
      "tensor([[-0.0486,  0.0343]])\n",
      "tensor([[-0.0620, -0.0009]])\n",
      "tensor([[ 0.0958, -0.0401]])\n",
      "tensor([[-0.0377, -0.0094]])\n",
      "tensor([[0.0871, 0.0584]])\n",
      "tensor([[0.0339, 0.0389]])\n",
      "tensor([[0.0283, 0.0777]])\n",
      "tensor([[ 0.1631, -0.1039]])\n",
      "tensor([[-0.0692,  0.0006]])\n",
      "tensor([[-0.0144, -0.1868]])\n",
      "epoch: 16 , loss: 0.00842183269560337\n",
      "tensor([[-0.0901, -0.0489]])\n",
      "tensor([[ 0.0358, -0.0151]])\n",
      "tensor([[ 0.0722, -0.0073]])\n",
      "tensor([[ 0.0483, -0.0260]])\n",
      "tensor([[0.0447, 0.0282]])\n",
      "tensor([[-0.0786,  0.0166]])\n",
      "tensor([[-0.0159,  0.0227]])\n",
      "tensor([[ 0.0243, -0.0212]])\n",
      "tensor([[-0.1014, -0.2110]])\n",
      "tensor([[-0.0396,  0.0996]])\n",
      "tensor([[ 0.1190, -0.0542]])\n",
      "tensor([[-0.1203,  0.1282]])\n",
      "tensor([[ 0.0344, -0.0140]])\n",
      "tensor([[0.0351, 0.1000]])\n",
      "tensor([[-0.0886,  0.0300]])\n",
      "tensor([[-0.0480, -0.1378]])\n",
      "tensor([[ 6.1170e-02, -5.5054e-05]])\n",
      "tensor([[ 0.0004, -0.0166]])\n",
      "tensor([[0.0178, 0.0366]])\n",
      "tensor([[0.0107, 0.0667]])\n",
      "epoch: 17 , loss: 0.008327288553118706\n",
      "tensor([[0.0301, 0.0031]])\n",
      "tensor([[ 0.0922, -0.0191]])\n",
      "tensor([[-0.0803, -0.0841]])\n",
      "tensor([[-0.0775, -0.0236]])\n",
      "tensor([[-0.0180,  0.0328]])\n",
      "tensor([[0.0544, 0.0411]])\n",
      "tensor([[-0.0527,  0.0111]])\n",
      "tensor([[ 0.0348, -0.0017]])\n",
      "tensor([[-0.0291, -0.0063]])\n",
      "tensor([[-0.0055,  0.0264]])\n",
      "tensor([[ 0.0698, -0.0159]])\n",
      "tensor([[ 0.0854, -0.0928]])\n",
      "tensor([[ 0.0407, -0.0055]])\n",
      "tensor([[-0.0631, -0.0251]])\n",
      "tensor([[-0.1107,  0.1276]])\n",
      "tensor([[-0.1062,  0.0298]])\n",
      "tensor([[ 0.0660, -0.0528]])\n",
      "tensor([[0.0523, 0.0031]])\n",
      "tensor([[-0.0825, -0.0095]])\n",
      "tensor([[0.0387, 0.0349]])\n",
      "epoch: 18 , loss: 0.00788072682917118\n",
      "tensor([[-0.0874, -0.0183]])\n",
      "tensor([[-0.0210,  0.0043]])\n",
      "tensor([[0.0020, 0.0643]])\n",
      "tensor([[-0.0024,  0.0085]])\n",
      "tensor([[ 0.0317, -0.0289]])\n",
      "tensor([[-0.0208, -0.0181]])\n",
      "tensor([[-0.0400, -0.1284]])\n",
      "tensor([[-0.0346, -0.0302]])\n",
      "tensor([[ 0.0999, -0.0905]])\n",
      "tensor([[0.0105, 0.0414]])\n",
      "tensor([[-0.0292,  0.0631]])\n",
      "tensor([[-0.0052,  0.0448]])\n",
      "tensor([[-0.0579, -0.1363]])\n",
      "tensor([[0.1445, 0.0463]])\n",
      "tensor([[ 0.0663, -0.0138]])\n",
      "tensor([[-0.0574, -0.0059]])\n",
      "tensor([[ 0.0326, -0.0470]])\n",
      "tensor([[0.0278, 0.0764]])\n",
      "tensor([[-0.0321,  0.0391]])\n",
      "tensor([[-0.0283,  0.1379]])\n",
      "epoch: 19 , loss: 0.012108314782381058\n",
      "tensor([[0.0028, 0.0061]])\n",
      "tensor([[-0.0514,  0.0385]])\n",
      "tensor([[ 0.0153, -0.0442]])\n",
      "tensor([[-0.0526,  0.0300]])\n",
      "tensor([[0.0101, 0.0583]])\n",
      "tensor([[-0.0041, -0.0128]])\n",
      "tensor([[0.0059, 0.0155]])\n",
      "tensor([[-0.0113,  0.0566]])\n",
      "tensor([[-0.0790, -0.0008]])\n",
      "tensor([[0.0726, 0.0167]])\n",
      "tensor([[-0.0092,  0.0108]])\n",
      "tensor([[ 0.1252, -0.0353]])\n",
      "tensor([[-0.0078, -0.0712]])\n",
      "tensor([[0.0399, 0.0120]])\n",
      "tensor([[0.0109, 0.0305]])\n",
      "tensor([[ 0.0347, -0.1276]])\n",
      "tensor([[-0.1376, -0.0012]])\n",
      "tensor([[-0.0265, -0.0530]])\n",
      "tensor([[-0.0296,  0.0452]])\n",
      "tensor([[ 0.0655, -0.0403]])\n",
      "epoch: 20 , loss: 0.009439362213015556\n",
      "tensor([[-0.0115, -0.0372]])\n",
      "tensor([[-0.0427,  0.0536]])\n",
      "tensor([[-0.0526, -0.1125]])\n",
      "tensor([[-0.0793, -0.0524]])\n",
      "tensor([[-0.0589, -0.0211]])\n",
      "tensor([[0.1322, 0.0110]])\n",
      "tensor([[ 0.0513, -0.0020]])\n",
      "tensor([[ 0.0116, -0.0063]])\n",
      "tensor([[-0.1645,  0.0400]])\n",
      "tensor([[-0.0315, -0.0379]])\n",
      "tensor([[-0.0018, -0.0165]])\n",
      "tensor([[0.0752, 0.0004]])\n",
      "tensor([[0.0622, 0.0460]])\n",
      "tensor([[-0.0273,  0.1123]])\n",
      "tensor([[0.0905, 0.1077]])\n",
      "tensor([[ 0.0351, -0.0249]])\n",
      "tensor([[0.0305, 0.0262]])\n",
      "tensor([[0.0159, 0.0052]])\n",
      "tensor([[-0.0480,  0.0082]])\n",
      "tensor([[ 0.0307, -0.0879]])\n",
      "epoch: 21 , loss: 0.009260020218789577\n",
      "tensor([[-0.0536, -0.0833]])\n",
      "tensor([[ 0.0023, -0.0113]])\n",
      "tensor([[ 0.0111, -0.0017]])\n",
      "tensor([[ 0.0603, -0.1075]])\n",
      "tensor([[ 0.0128, -0.0258]])\n",
      "tensor([[-0.0090,  0.0154]])\n",
      "tensor([[-0.0733,  0.0272]])\n",
      "tensor([[-0.0746,  0.0816]])\n",
      "tensor([[0.0408, 0.0903]])\n",
      "tensor([[-0.0862,  0.0064]])\n",
      "tensor([[-0.0587,  0.0987]])\n",
      "tensor([[ 0.0125, -0.0952]])\n",
      "tensor([[0.0843, 0.0307]])\n",
      "tensor([[ 0.0365, -0.0696]])\n",
      "tensor([[0.0315, 0.0569]])\n",
      "tensor([[ 0.0015, -0.0595]])\n",
      "tensor([[-0.0211,  0.0641]])\n",
      "tensor([[-0.0151,  0.0047]])\n",
      "tensor([[ 0.1174, -0.1048]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0178,  0.0950]])\n",
      "epoch: 22 , loss: 0.009754937142133713\n",
      "tensor([[0.0215, 0.0534]])\n",
      "tensor([[-0.0554, -0.0056]])\n",
      "tensor([[-0.0107, -0.0634]])\n",
      "tensor([[-0.1278, -0.2102]])\n",
      "tensor([[-0.0359,  0.0357]])\n",
      "tensor([[ 0.1458, -0.0275]])\n",
      "tensor([[-0.0051,  0.0758]])\n",
      "tensor([[-0.1031,  0.0482]])\n",
      "tensor([[0.0824, 0.0308]])\n",
      "tensor([[-0.0943, -0.0560]])\n",
      "tensor([[0.0388, 0.0377]])\n",
      "tensor([[-0.0465,  0.0527]])\n",
      "tensor([[ 0.0076, -0.0438]])\n",
      "tensor([[ 0.0383, -0.0459]])\n",
      "tensor([[-0.0375,  0.0557]])\n",
      "tensor([[-0.0703, -0.0537]])\n",
      "tensor([[-0.0174,  0.0287]])\n",
      "tensor([[ 0.1529, -0.0271]])\n",
      "tensor([[0.1020, 0.1050]])\n",
      "tensor([[0.0388, 0.0217]])\n",
      "epoch: 23 , loss: 0.007751493714749813\n",
      "tensor([[0.0071, 0.0221]])\n",
      "tensor([[ 0.0463, -0.0469]])\n",
      "tensor([[ 0.0634, -0.0338]])\n",
      "tensor([[ 0.1448, -0.0578]])\n",
      "tensor([[-0.0194,  0.0689]])\n",
      "tensor([[0.1320, 0.0047]])\n",
      "tensor([[-0.0225, -0.0249]])\n",
      "tensor([[-0.0597, -0.0966]])\n",
      "tensor([[-0.1034,  0.1024]])\n",
      "tensor([[-0.0072,  0.1611]])\n",
      "tensor([[-0.0189, -0.0170]])\n",
      "tensor([[ 0.0100, -0.0389]])\n",
      "tensor([[-0.0522, -0.0547]])\n",
      "tensor([[-0.0477,  0.0929]])\n",
      "tensor([[-0.0149,  0.0008]])\n",
      "tensor([[ 0.0234, -0.0764]])\n",
      "tensor([[0.0046, 0.0085]])\n",
      "tensor([[-0.0734, -0.0984]])\n",
      "tensor([[-0.0523,  0.0409]])\n",
      "tensor([[-0.0757,  0.0135]])\n",
      "epoch: 24 , loss: 0.006396350916475058\n",
      "tensor([[ 0.1467, -0.0116]])\n",
      "tensor([[-0.0137,  0.0081]])\n",
      "tensor([[-0.0922, -0.1327]])\n",
      "tensor([[-0.0585, -0.0093]])\n",
      "tensor([[-0.0945, -0.0045]])\n",
      "tensor([[-0.0619,  0.1733]])\n",
      "tensor([[0.0203, 0.0350]])\n",
      "tensor([[-0.0198,  0.0044]])\n",
      "tensor([[-0.1149, -0.0309]])\n",
      "tensor([[ 0.0093, -0.0238]])\n",
      "tensor([[-0.1048, -0.0170]])\n",
      "tensor([[ 0.0835, -0.0142]])\n",
      "tensor([[0.0418, 0.0108]])\n",
      "tensor([[ 0.0792, -0.0243]])\n",
      "tensor([[-0.0644, -0.0330]])\n",
      "tensor([[0.0978, 0.0323]])\n",
      "tensor([[0.0142, 0.0387]])\n",
      "tensor([[ 0.0298, -0.0560]])\n",
      "tensor([[0.1039, 0.0220]])\n",
      "tensor([[0.0632, 0.0338]])\n",
      "epoch: 25 , loss: 0.005314805544912815\n",
      "tensor([[-0.0706,  0.0385]])\n",
      "tensor([[-0.0892, -0.1309]])\n",
      "tensor([[0.1626, 0.1312]])\n",
      "tensor([[0.0722, 0.0318]])\n",
      "tensor([[-0.0711,  0.1057]])\n",
      "tensor([[-0.0078,  0.0001]])\n",
      "tensor([[-0.0435, -0.1243]])\n",
      "tensor([[0.0437, 0.0178]])\n",
      "tensor([[-0.0091, -0.0366]])\n",
      "tensor([[-0.0025, -0.0206]])\n",
      "tensor([[0.1744, 0.0054]])\n",
      "tensor([[ 0.0176, -0.0795]])\n",
      "tensor([[-0.1321,  0.1877]])\n",
      "tensor([[0.0204, 0.0277]])\n",
      "tensor([[-0.0209,  0.0287]])\n",
      "tensor([[-0.0681, -0.0681]])\n",
      "tensor([[-0.0633,  0.0343]])\n",
      "tensor([[-0.0508, -0.0794]])\n",
      "tensor([[ 0.0541, -0.0031]])\n",
      "tensor([[ 0.0628, -0.1052]])\n",
      "epoch: 26 , loss: 0.0179135799407959\n",
      "tensor([[0.0120, 0.1303]])\n",
      "tensor([[-0.0828,  0.0032]])\n",
      "tensor([[0.0108, 0.0584]])\n",
      "tensor([[-0.1072,  0.0492]])\n",
      "tensor([[-0.1766, -0.1084]])\n",
      "tensor([[0.0564, 0.0319]])\n",
      "tensor([[ 0.0120, -0.1497]])\n",
      "tensor([[0.0127, 0.0962]])\n",
      "tensor([[0.0069, 0.0134]])\n",
      "tensor([[-0.0601, -0.0384]])\n",
      "tensor([[0.0660, 0.1189]])\n",
      "tensor([[0.0403, 0.0400]])\n",
      "tensor([[ 0.0699, -0.1339]])\n",
      "tensor([[0.0204, 0.0296]])\n",
      "tensor([[-0.0456,  0.0125]])\n",
      "tensor([[ 0.0726, -0.0977]])\n",
      "tensor([[0.0343, 0.0202]])\n",
      "tensor([[ 0.0637, -0.0535]])\n",
      "tensor([[ 0.0418, -0.0304]])\n",
      "tensor([[-0.0209, -0.0300]])\n",
      "epoch: 27 , loss: 0.01248681079596281\n",
      "tensor([[-0.0472,  0.0652]])\n",
      "tensor([[-0.0523, -0.1364]])\n",
      "tensor([[0.0863, 0.1205]])\n",
      "tensor([[-0.0534, -0.1067]])\n",
      "tensor([[-0.0922, -0.1026]])\n",
      "tensor([[ 0.0548, -0.1062]])\n",
      "tensor([[-0.1552,  0.0612]])\n",
      "tensor([[0.2117, 0.0850]])\n",
      "tensor([[ 0.0571, -0.0375]])\n",
      "tensor([[0.0388, 0.0626]])\n",
      "tensor([[-0.0060,  0.0539]])\n",
      "tensor([[0.0224, 0.0146]])\n",
      "tensor([[0.1063, 0.0785]])\n",
      "tensor([[-0.1323,  0.0026]])\n",
      "tensor([[-0.0220, -0.0219]])\n",
      "tensor([[0.0407, 0.0071]])\n",
      "tensor([[0.0781, 0.0420]])\n",
      "tensor([[-0.1308, -0.0348]])\n",
      "tensor([[0.0538, 0.0440]])\n",
      "tensor([[-0.0811, -0.0666]])\n",
      "epoch: 28 , loss: 0.0070188455283641815\n",
      "tensor([[-0.1066, -0.0028]])\n",
      "tensor([[ 0.0454, -0.0225]])\n",
      "tensor([[-0.0839,  0.0029]])\n",
      "tensor([[0.0283, 0.0913]])\n",
      "tensor([[0.0037, 0.0618]])\n",
      "tensor([[-0.0554,  0.0946]])\n",
      "tensor([[-0.0071, -0.0429]])\n",
      "tensor([[0.0358, 0.0177]])\n",
      "tensor([[-0.0168,  0.0195]])\n",
      "tensor([[-0.0055, -0.0151]])\n",
      "tensor([[-0.0621, -0.0637]])\n",
      "tensor([[0.0102, 0.0490]])\n",
      "tensor([[-0.0250, -0.0043]])\n",
      "tensor([[-0.1356, -0.1129]])\n",
      "tensor([[0.0985, 0.0048]])\n",
      "tensor([[ 0.0621, -0.0067]])\n",
      "tensor([[ 0.0621, -0.0907]])\n",
      "tensor([[0.0552, 0.0439]])\n",
      "tensor([[0.0282, 0.0551]])\n",
      "tensor([[ 0.1184, -0.1159]])\n",
      "epoch: 29 , loss: 0.013417994603514671\n",
      "tensor([[-0.1092, -0.1215]])\n",
      "tensor([[ 0.0216, -0.0685]])\n",
      "tensor([[-0.0171,  0.0635]])\n",
      "tensor([[0.0439, 0.0424]])\n",
      "tensor([[-0.0775,  0.0645]])\n",
      "tensor([[-0.0452, -0.0035]])\n",
      "tensor([[ 0.0427, -0.0274]])\n",
      "tensor([[0.0404, 0.0071]])\n",
      "tensor([[ 0.0430, -0.0760]])\n",
      "tensor([[0.0205, 0.0706]])\n",
      "tensor([[0.0292, 0.1248]])\n",
      "tensor([[-0.0574,  0.0997]])\n",
      "tensor([[ 0.0454, -0.0129]])\n",
      "tensor([[ 0.0754, -0.0475]])\n",
      "tensor([[0.0417, 0.0220]])\n",
      "tensor([[-0.0858,  0.0219]])\n",
      "tensor([[-0.0869, -0.0943]])\n",
      "tensor([[0.0754, 0.0471]])\n",
      "tensor([[ 0.0012, -0.0456]])\n",
      "tensor([[-0.0300, -0.0530]])\n",
      "epoch: 30 , loss: 0.0030951856169849634\n",
      "tensor([[-0.0944, -0.1111]])\n",
      "tensor([[-0.0240,  0.0519]])\n",
      "tensor([[0.0800, 0.0452]])\n",
      "tensor([[-0.0217, -0.0845]])\n",
      "tensor([[ 0.0432, -0.0171]])\n",
      "tensor([[-0.0069,  0.0070]])\n",
      "tensor([[-0.0063, -0.0499]])\n",
      "tensor([[ 0.0983, -0.0834]])\n",
      "tensor([[-0.0753,  0.0369]])\n",
      "tensor([[-0.0285, -0.0059]])\n",
      "tensor([[-0.1121,  0.0542]])\n",
      "tensor([[ 0.0222, -0.0517]])\n",
      "tensor([[-0.0132,  0.0459]])\n",
      "tensor([[0.0211, 0.0668]])\n",
      "tensor([[ 0.0440, -0.0569]])\n",
      "tensor([[0.1307, 0.0261]])\n",
      "tensor([[0.0180, 0.1121]])\n",
      "tensor([[-0.0578,  0.0168]])\n",
      "tensor([[ 0.0721, -0.1083]])\n",
      "tensor([[-0.0968,  0.1657]])\n",
      "epoch: 31 , loss: 0.020725509151816368\n",
      "tensor([[ 0.0021, -0.0563]])\n",
      "tensor([[ 0.0941, -0.0334]])\n",
      "tensor([[-0.0182,  0.0629]])\n",
      "tensor([[-0.1189, -0.0368]])\n",
      "tensor([[0.0517, 0.1402]])\n",
      "tensor([[-0.0355, -0.0933]])\n",
      "tensor([[-0.0208, -0.0293]])\n",
      "tensor([[-0.0426, -0.0636]])\n",
      "tensor([[0.0287, 0.0330]])\n",
      "tensor([[0.1019, 0.0843]])\n",
      "tensor([[-0.0374, -0.0184]])\n",
      "tensor([[-0.0561, -0.0316]])\n",
      "tensor([[-0.0021, -0.0832]])\n",
      "tensor([[-0.0581,  0.0013]])\n",
      "tensor([[0.0254, 0.1070]])\n",
      "tensor([[0.0100, 0.0023]])\n",
      "tensor([[0.0817, 0.0895]])\n",
      "tensor([[ 0.0014, -0.0097]])\n",
      "tensor([[0.0084, 0.0402]])\n",
      "tensor([[-0.0317, -0.1087]])\n",
      "epoch: 32 , loss: 0.01035118568688631\n",
      "tensor([[0.0220, 0.0088]])\n",
      "tensor([[0.0292, 0.0305]])\n",
      "tensor([[-0.1406,  0.0211]])\n",
      "tensor([[ 0.0003, -0.0598]])\n",
      "tensor([[0.0261, 0.1332]])\n",
      "tensor([[-0.0082, -0.0118]])\n",
      "tensor([[-0.0541, -0.0736]])\n",
      "tensor([[0.0579, 0.0405]])\n",
      "tensor([[ 0.0229, -0.0779]])\n",
      "tensor([[ 0.0167, -0.0529]])\n",
      "tensor([[-0.0653,  0.0200]])\n",
      "tensor([[0.0020, 0.0222]])\n",
      "tensor([[0.0947, 0.0571]])\n",
      "tensor([[-0.0434,  0.0199]])\n",
      "tensor([[-0.0838, -0.0208]])\n",
      "tensor([[-0.0337, -0.0503]])\n",
      "tensor([[-0.0558, -0.0549]])\n",
      "tensor([[0.0240, 0.0052]])\n",
      "tensor([[0.1293, 0.0699]])\n",
      "tensor([[ 0.0826, -0.0432]])\n",
      "epoch: 33 , loss: 0.004854024853557348\n",
      "tensor([[-0.0414, -0.0050]])\n",
      "tensor([[-0.0066,  0.0056]])\n",
      "tensor([[ 0.0321, -0.0192]])\n",
      "tensor([[-0.0205, -0.0731]])\n",
      "tensor([[-0.0477, -0.0614]])\n",
      "tensor([[ 0.0220, -0.0806]])\n",
      "tensor([[-0.0217,  0.0291]])\n",
      "tensor([[-0.1268,  0.0595]])\n",
      "tensor([[-0.0600, -0.0793]])\n",
      "tensor([[-0.0024,  0.0506]])\n",
      "tensor([[ 0.1470, -0.0265]])\n",
      "tensor([[0.0629, 0.0332]])\n",
      "tensor([[0.0311, 0.0022]])\n",
      "tensor([[0.0253, 0.0019]])\n",
      "tensor([[-0.0377,  0.0457]])\n",
      "tensor([[0.1305, 0.0066]])\n",
      "tensor([[-0.0791, -0.0518]])\n",
      "tensor([[0.0614, 0.0320]])\n",
      "tensor([[0.0650, 0.1094]])\n",
      "tensor([[-0.1323,  0.0699]])\n",
      "epoch: 34 , loss: 0.01030554436147213\n",
      "tensor([[ 0.0597, -0.0310]])\n",
      "tensor([[-0.0278, -0.0674]])\n",
      "tensor([[-0.0129,  0.2242]])\n",
      "tensor([[-0.0389, -0.0143]])\n",
      "tensor([[-0.0287,  0.0988]])\n",
      "tensor([[-0.0272, -0.0352]])\n",
      "tensor([[0.0721, 0.0338]])\n",
      "tensor([[ 0.0520, -0.0641]])\n",
      "tensor([[-0.0830, -0.0356]])\n",
      "tensor([[0.0658, 0.0767]])\n",
      "tensor([[ 0.0558, -0.0874]])\n",
      "tensor([[ 0.0219, -0.0207]])\n",
      "tensor([[-0.0012, -0.0113]])\n",
      "tensor([[-0.0403,  0.0781]])\n",
      "tensor([[ 0.0154, -0.0117]])\n",
      "tensor([[-0.0850,  0.0666]])\n",
      "tensor([[ 0.1010, -0.0569]])\n",
      "tensor([[-0.0018, -0.0526]])\n",
      "tensor([[-0.0399, -0.0675]])\n",
      "tensor([[-0.1039, -0.0894]])\n",
      "epoch: 35 , loss: 0.010621139779686928\n",
      "tensor([[-0.1048, -0.0519]])\n",
      "tensor([[0.0062, 0.0312]])\n",
      "tensor([[-0.0907,  0.0838]])\n",
      "tensor([[-0.0338,  0.1605]])\n",
      "tensor([[ 0.0380, -0.0101]])\n",
      "tensor([[-0.0621,  0.0091]])\n",
      "tensor([[0.0218, 0.0046]])\n",
      "tensor([[-0.0221, -0.0063]])\n",
      "tensor([[0.0683, 0.0385]])\n",
      "tensor([[-0.0140, -0.0146]])\n",
      "tensor([[-0.1086, -0.0629]])\n",
      "tensor([[0.0664, 0.0780]])\n",
      "tensor([[0.1380, 0.0478]])\n",
      "tensor([[ 0.1141, -0.0428]])\n",
      "tensor([[-0.0456, -0.0197]])\n",
      "tensor([[ 0.0553, -0.1259]])\n",
      "tensor([[ 0.0427, -0.1153]])\n",
      "tensor([[ 0.0004, -0.0139]])\n",
      "tensor([[-0.0325,  0.0289]])\n",
      "tensor([[-0.0045, -0.0671]])\n",
      "epoch: 36 , loss: 0.006628037896007299\n",
      "tensor([[0.0037, 0.0634]])\n",
      "tensor([[-0.0606,  0.0701]])\n",
      "tensor([[-0.1092, -0.0267]])\n",
      "tensor([[0.1028, 0.0232]])\n",
      "tensor([[ 0.0020, -0.0007]])\n",
      "tensor([[-0.1055,  0.0608]])\n",
      "tensor([[-0.0520,  0.0395]])\n",
      "tensor([[ 0.1012, -0.1029]])\n",
      "tensor([[-0.0421,  0.0760]])\n",
      "tensor([[ 0.0293, -0.1337]])\n",
      "tensor([[0.0075, 0.0065]])\n",
      "tensor([[0.0650, 0.0838]])\n",
      "tensor([[ 0.0108, -0.0694]])\n",
      "tensor([[ 0.0118, -0.0141]])\n",
      "tensor([[ 0.0011, -0.0520]])\n",
      "tensor([[0.0400, 0.0270]])\n",
      "tensor([[ 0.0405, -0.0027]])\n",
      "tensor([[ 0.0821, -0.0430]])\n",
      "tensor([[-0.0817,  0.0031]])\n",
      "tensor([[-0.0433, -0.0231]])\n",
      "epoch: 37 , loss: 0.02284068986773491\n",
      "tensor([[-0.0709,  0.1353]])\n",
      "tensor([[-0.0870, -0.0442]])\n",
      "tensor([[ 0.0183, -0.1328]])\n",
      "tensor([[-0.1173, -0.0305]])\n",
      "tensor([[0.0149, 0.0111]])\n",
      "tensor([[ 0.0205, -0.0041]])\n",
      "tensor([[0.0290, 0.0234]])\n",
      "tensor([[-0.0011,  0.0030]])\n",
      "tensor([[ 0.0316, -0.0148]])\n",
      "tensor([[ 0.0735, -0.0289]])\n",
      "tensor([[0.0474, 0.0584]])\n",
      "tensor([[ 0.0416, -0.0514]])\n",
      "tensor([[-0.0228,  0.0702]])\n",
      "tensor([[ 0.0520, -0.0164]])\n",
      "tensor([[0.0529, 0.0628]])\n",
      "tensor([[0.0828, 0.1470]])\n",
      "tensor([[-0.1287, -0.0506]])\n",
      "tensor([[-0.0477,  0.0298]])\n",
      "tensor([[ 0.0890, -0.0730]])\n",
      "tensor([[-0.0669, -0.0728]])\n",
      "epoch: 38 , loss: 0.00979048665612936\n",
      "tensor([[0.0049, 0.0029]])\n",
      "tensor([[-0.1557,  0.0453]])\n",
      "tensor([[-0.0044, -0.0641]])\n",
      "tensor([[0.0091, 0.0099]])\n",
      "tensor([[-0.0468, -0.0214]])\n",
      "tensor([[-0.0205,  0.0631]])\n",
      "tensor([[ 0.1281, -0.0335]])\n",
      "tensor([[-0.0585, -0.0678]])\n",
      "tensor([[ 0.0573, -0.1009]])\n",
      "tensor([[ 0.1659, -0.0071]])\n",
      "tensor([[-0.0561, -0.0283]])\n",
      "tensor([[ 0.0275, -0.0484]])\n",
      "tensor([[0.0062, 0.0917]])\n",
      "tensor([[0.0413, 0.0342]])\n",
      "tensor([[ 0.0021, -0.0516]])\n",
      "tensor([[ 0.0088, -0.0123]])\n",
      "tensor([[-0.0422,  0.0216]])\n",
      "tensor([[0.0842, 0.0848]])\n",
      "tensor([[-0.1049,  0.0668]])\n",
      "tensor([[-0.0659,  0.0664]])\n",
      "epoch: 39 , loss: 0.011404327116906643\n",
      "tensor([[-0.0832, -0.0234]])\n",
      "tensor([[ 0.1494, -0.0067]])\n",
      "tensor([[-0.0532,  0.0204]])\n",
      "tensor([[-0.0092,  0.0221]])\n",
      "tensor([[-0.0499,  0.1028]])\n",
      "tensor([[-0.0648,  0.0458]])\n",
      "tensor([[-0.0431, -0.0181]])\n",
      "tensor([[-0.0245, -0.0250]])\n",
      "tensor([[-0.0608, -0.0539]])\n",
      "tensor([[ 0.0534, -0.0645]])\n",
      "tensor([[0.0158, 0.0323]])\n",
      "tensor([[ 0.0189, -0.0538]])\n",
      "tensor([[0.0217, 0.1339]])\n",
      "tensor([[ 0.0194, -0.0545]])\n",
      "tensor([[ 0.0720, -0.0523]])\n",
      "tensor([[-0.0576,  0.0372]])\n",
      "tensor([[-0.0727,  0.0010]])\n",
      "tensor([[ 0.0226, -0.0477]])\n",
      "tensor([[ 0.1423, -0.0077]])\n",
      "tensor([[ 0.0280, -0.0048]])\n",
      "epoch: 40 , loss: 0.010638998821377754\n",
      "tensor([[-0.0600, -0.0770]])\n",
      "tensor([[0.0463, 0.0265]])\n",
      "tensor([[-0.0529,  0.1057]])\n",
      "tensor([[0.0416, 0.0151]])\n",
      "tensor([[ 0.0467, -0.0893]])\n",
      "tensor([[0.0701, 0.0110]])\n",
      "tensor([[ 0.0649, -0.0364]])\n",
      "tensor([[ 0.0822, -0.0430]])\n",
      "tensor([[-0.0363, -0.0553]])\n",
      "tensor([[-0.0206, -0.0420]])\n",
      "tensor([[ 0.0353, -0.0898]])\n",
      "tensor([[-0.2087,  0.1644]])\n",
      "tensor([[-0.0354,  0.1287]])\n",
      "tensor([[ 0.0093, -0.0093]])\n",
      "tensor([[-0.0085, -0.0228]])\n",
      "tensor([[-0.0460, -0.0157]])\n",
      "tensor([[0.0708, 0.0712]])\n",
      "tensor([[-0.0471, -0.0400]])\n",
      "tensor([[-0.0753, -0.0012]])\n",
      "tensor([[0.0830, 0.0240]])\n",
      "epoch: 41 , loss: 0.006548972334712744\n",
      "tensor([[ 0.0094, -0.0179]])\n",
      "tensor([[0.0196, 0.0033]])\n",
      "tensor([[-0.0560,  0.0002]])\n",
      "tensor([[0.0455, 0.0129]])\n",
      "tensor([[-0.1193, -0.0255]])\n",
      "tensor([[-0.0522, -0.1225]])\n",
      "tensor([[0.0157, 0.0343]])\n",
      "tensor([[-0.0233, -0.0496]])\n",
      "tensor([[ 0.0359, -0.0099]])\n",
      "tensor([[-0.0118,  0.0836]])\n",
      "tensor([[-0.1222, -0.0828]])\n",
      "tensor([[0.0704, 0.0306]])\n",
      "tensor([[-0.0425,  0.0166]])\n",
      "tensor([[0.0565, 0.1046]])\n",
      "tensor([[ 0.0594, -0.0011]])\n",
      "tensor([[0.0938, 0.0580]])\n",
      "tensor([[0.0664, 0.0706]])\n",
      "tensor([[-0.0967,  0.0626]])\n",
      "tensor([[ 0.0912, -0.0515]])\n",
      "tensor([[-0.0115, -0.0993]])\n",
      "epoch: 42 , loss: 0.006323479115962982\n",
      "tensor([[ 0.0048, -0.1043]])\n",
      "tensor([[0.0074, 0.0063]])\n",
      "tensor([[-0.0170, -0.0893]])\n",
      "tensor([[-0.0384, -0.0548]])\n",
      "tensor([[0.0684, 0.0178]])\n",
      "tensor([[-0.0188,  0.0351]])\n",
      "tensor([[-0.0543, -0.0833]])\n",
      "tensor([[0.0433, 0.0046]])\n",
      "tensor([[ 0.0525, -0.0401]])\n",
      "tensor([[0.0695, 0.0337]])\n",
      "tensor([[-0.0235, -0.0457]])\n",
      "tensor([[0.0215, 0.1548]])\n",
      "tensor([[-0.0603, -0.0763]])\n",
      "tensor([[ 0.0133, -0.0471]])\n",
      "tensor([[-0.0136,  0.0624]])\n",
      "tensor([[0.0746, 0.0323]])\n",
      "tensor([[-0.0821,  0.0466]])\n",
      "tensor([[-0.0531,  0.1233]])\n",
      "tensor([[0.0839, 0.0610]])\n",
      "tensor([[-0.1028,  0.0310]])\n",
      "epoch: 43 , loss: 0.012404234148561954\n",
      "tensor([[ 0.2040, -0.0095]])\n",
      "tensor([[-0.1431,  0.0665]])\n",
      "tensor([[-0.0041,  0.0536]])\n",
      "tensor([[-0.0531, -0.0786]])\n",
      "tensor([[-0.0805, -0.0883]])\n",
      "tensor([[ 0.0076, -0.0208]])\n",
      "tensor([[-0.0577,  0.0192]])\n",
      "tensor([[-0.0211, -0.0730]])\n",
      "tensor([[ 0.0285, -0.0371]])\n",
      "tensor([[0.0378, 0.0625]])\n",
      "tensor([[0.0040, 0.0833]])\n",
      "tensor([[ 0.0170, -0.0450]])\n",
      "tensor([[0.1077, 0.0040]])\n",
      "tensor([[-0.0401,  0.0091]])\n",
      "tensor([[0.0501, 0.0424]])\n",
      "tensor([[0.0501, 0.0162]])\n",
      "tensor([[-0.0047,  0.0262]])\n",
      "tensor([[-0.0519, -0.1004]])\n",
      "tensor([[-0.0560, -0.0058]])\n",
      "tensor([[-0.0076,  0.0529]])\n",
      "epoch: 44 , loss: 0.009024078026413918\n",
      "tensor([[ 0.0508, -0.0815]])\n",
      "tensor([[-0.0398, -0.0214]])\n",
      "tensor([[-0.0813,  0.0042]])\n",
      "tensor([[-0.0474, -0.0377]])\n",
      "tensor([[0.1283, 0.0925]])\n",
      "tensor([[0.0286, 0.1150]])\n",
      "tensor([[-0.0041, -0.0019]])\n",
      "tensor([[-0.1018, -0.0904]])\n",
      "tensor([[ 0.0497, -0.0286]])\n",
      "tensor([[ 0.0531, -0.0641]])\n",
      "tensor([[-0.0318, -0.0019]])\n",
      "tensor([[ 0.0206, -0.0605]])\n",
      "tensor([[-0.0071, -0.0904]])\n",
      "tensor([[-0.0332,  0.0784]])\n",
      "tensor([[0.0331, 0.1326]])\n",
      "tensor([[ 0.0457, -0.0992]])\n",
      "tensor([[-0.0848, -0.0368]])\n",
      "tensor([[-0.0802,  0.1135]])\n",
      "tensor([[0.0715, 0.0286]])\n",
      "tensor([[0.0308, 0.0530]])\n",
      "epoch: 45 , loss: 0.007561509497463703\n",
      "tensor([[0.0376, 0.0396]])\n",
      "tensor([[-0.0436,  0.0019]])\n",
      "tensor([[0.0520, 0.0461]])\n",
      "tensor([[0.1001, 0.0190]])\n",
      "tensor([[-0.0389, -0.2448]])\n",
      "tensor([[0.0425, 0.0539]])\n",
      "tensor([[-0.1627, -0.0051]])\n",
      "tensor([[-0.0394, -0.0320]])\n",
      "tensor([[ 0.0345, -0.0365]])\n",
      "tensor([[-0.0101, -0.0253]])\n",
      "tensor([[-0.0003,  0.0106]])\n",
      "tensor([[-0.0706, -0.0771]])\n",
      "tensor([[ 0.0581, -0.0607]])\n",
      "tensor([[-0.0340, -0.0694]])\n",
      "tensor([[0.0431, 0.0227]])\n",
      "tensor([[-0.0421,  0.0647]])\n",
      "tensor([[0.0234, 0.0130]])\n",
      "tensor([[-0.0024,  0.0768]])\n",
      "tensor([[0.0144, 0.1521]])\n",
      "tensor([[0.0288, 0.0753]])\n",
      "epoch: 46 , loss: 0.005480831488966942\n",
      "tensor([[ 0.0073, -0.0266]])\n",
      "tensor([[-0.0829, -0.0349]])\n",
      "tensor([[ 0.0309, -0.0303]])\n",
      "tensor([[-0.0346,  0.0332]])\n",
      "tensor([[-0.0296, -0.0204]])\n",
      "tensor([[ 0.0286, -0.0195]])\n",
      "tensor([[ 0.1202, -0.0036]])\n",
      "tensor([[0.0539, 0.0759]])\n",
      "tensor([[0.0180, 0.1863]])\n",
      "tensor([[-0.1297, -0.0933]])\n",
      "tensor([[ 0.0427, -0.0158]])\n",
      "tensor([[-0.0150,  0.0128]])\n",
      "tensor([[0.0198, 0.1326]])\n",
      "tensor([[-0.0113,  0.0148]])\n",
      "tensor([[-0.0343,  0.0131]])\n",
      "tensor([[ 0.0018, -0.0436]])\n",
      "tensor([[ 0.0883, -0.0281]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0783, -0.0588]])\n",
      "tensor([[ 0.0562, -0.1311]])\n",
      "tensor([[-0.0619, -0.0130]])\n",
      "epoch: 47 , loss: 0.005480319261550903\n",
      "tensor([[0.0728, 0.0874]])\n",
      "tensor([[0.0896, 0.0305]])\n",
      "tensor([[-0.0528, -0.0826]])\n",
      "tensor([[ 0.0689, -0.0262]])\n",
      "tensor([[ 0.1163, -0.0103]])\n",
      "tensor([[0.1328, 0.0381]])\n",
      "tensor([[-0.0124,  0.0306]])\n",
      "tensor([[-0.0294, -0.0074]])\n",
      "tensor([[-0.0807,  0.0194]])\n",
      "tensor([[-0.0430, -0.0483]])\n",
      "tensor([[-0.0973,  0.0601]])\n",
      "tensor([[-0.0450,  0.0625]])\n",
      "tensor([[ 0.0359, -0.0317]])\n",
      "tensor([[0.0069, 0.0269]])\n",
      "tensor([[-0.0521, -0.0653]])\n",
      "tensor([[ 0.0120, -0.0145]])\n",
      "tensor([[-0.0728,  0.0735]])\n",
      "tensor([[0.0106, 0.0533]])\n",
      "tensor([[-0.1442, -0.1094]])\n",
      "tensor([[-0.0026, -0.1384]])\n",
      "epoch: 48 , loss: 0.008990136906504631\n",
      "tensor([[-0.0628, -0.1194]])\n",
      "tensor([[-0.1004,  0.0092]])\n",
      "tensor([[-0.0571,  0.0675]])\n",
      "tensor([[-0.0146, -0.0181]])\n",
      "tensor([[0.0297, 0.0191]])\n",
      "tensor([[-0.0247,  0.1059]])\n",
      "tensor([[0.0661, 0.1198]])\n",
      "tensor([[-0.0820,  0.1362]])\n",
      "tensor([[ 0.0155, -0.0381]])\n",
      "tensor([[ 0.0251, -0.0397]])\n",
      "tensor([[-0.0998,  0.0081]])\n",
      "tensor([[ 0.0763, -0.0363]])\n",
      "tensor([[ 0.0698, -0.1000]])\n",
      "tensor([[ 0.0644, -0.0102]])\n",
      "tensor([[-0.0121, -0.0288]])\n",
      "tensor([[-0.0431, -0.0741]])\n",
      "tensor([[ 0.1498, -0.0222]])\n",
      "tensor([[ 0.0308, -0.0978]])\n",
      "tensor([[0.0390, 0.0509]])\n",
      "tensor([[0.0384, 0.0477]])\n",
      "epoch: 49 , loss: 0.007691276725381613\n",
      "tensor([[-0.0004,  0.0099]])\n",
      "tensor([[-0.0652, -0.0794]])\n",
      "tensor([[-0.0128, -0.0525]])\n",
      "tensor([[-0.0853,  0.0353]])\n",
      "tensor([[-0.0206,  0.0644]])\n",
      "tensor([[-0.0249,  0.0948]])\n",
      "tensor([[0.1992, 0.0101]])\n",
      "tensor([[-0.0183, -0.0480]])\n",
      "tensor([[ 0.0391, -0.0522]])\n",
      "tensor([[0.1034, 0.0098]])\n",
      "tensor([[ 0.1070, -0.0295]])\n",
      "tensor([[-0.0395,  0.0564]])\n",
      "tensor([[-0.0012, -0.0185]])\n",
      "tensor([[-0.0135, -0.0459]])\n",
      "tensor([[-0.0247,  0.0051]])\n",
      "tensor([[-0.0716,  0.0568]])\n",
      "tensor([[-0.0274, -0.0203]])\n",
      "tensor([[0.0130, 0.0352]])\n",
      "tensor([[-0.0704,  0.0040]])\n",
      "tensor([[-0.0040, -0.0199]])\n",
      "epoch: 50 , loss: 0.004343679640442133\n",
      "tensor([[ 0.0003, -0.0403]])\n",
      "tensor([[-0.0348,  0.0748]])\n",
      "tensor([[-0.1185, -0.0114]])\n",
      "tensor([[ 0.0298, -0.0644]])\n",
      "tensor([[ 0.0104, -0.0702]])\n",
      "tensor([[ 0.0950, -0.0633]])\n",
      "tensor([[ 0.0228, -0.0290]])\n",
      "tensor([[ 0.0247, -0.0106]])\n",
      "tensor([[0.0186, 0.0078]])\n",
      "tensor([[0.0842, 0.0383]])\n",
      "tensor([[0.1144, 0.0576]])\n",
      "tensor([[0.0445, 0.0881]])\n",
      "tensor([[-0.1085, -0.0242]])\n",
      "tensor([[-0.0035,  0.0282]])\n",
      "tensor([[-0.0121, -0.0147]])\n",
      "tensor([[-0.1307,  0.0501]])\n",
      "tensor([[0.0735, 0.0475]])\n",
      "tensor([[-0.1606, -0.0682]])\n",
      "tensor([[-0.0229, -0.0192]])\n",
      "tensor([[0.0492, 0.0622]])\n",
      "epoch: 51 , loss: 0.006807966623455286\n",
      "tensor([[-0.0119, -0.0249]])\n",
      "tensor([[-0.0620,  0.0799]])\n",
      "tensor([[-0.0381, -0.0456]])\n",
      "tensor([[-0.0309,  0.0378]])\n",
      "tensor([[-0.0754, -0.0358]])\n",
      "tensor([[-0.0643, -0.0090]])\n",
      "tensor([[ 0.0854, -0.0576]])\n",
      "tensor([[-0.0340,  0.0189]])\n",
      "tensor([[0.0143, 0.0705]])\n",
      "tensor([[0.0814, 0.2019]])\n",
      "tensor([[0.0870, 0.0923]])\n",
      "tensor([[-0.1083, -0.0648]])\n",
      "tensor([[ 0.0560, -0.0226]])\n",
      "tensor([[0.1169, 0.0187]])\n",
      "tensor([[0.0863, 0.0161]])\n",
      "tensor([[ 0.0207, -0.1795]])\n",
      "tensor([[ 0.0051, -0.0738]])\n",
      "tensor([[-0.0922,  0.0088]])\n",
      "tensor([[ 0.0647, -0.0247]])\n",
      "tensor([[-0.0674, -0.0506]])\n",
      "epoch: 52 , loss: 0.006148114334791899\n",
      "tensor([[0.0180, 0.0117]])\n",
      "tensor([[-0.0365, -0.0280]])\n",
      "tensor([[ 0.0882, -0.0583]])\n",
      "tensor([[-0.0459,  0.0867]])\n",
      "tensor([[-0.1661, -0.0901]])\n",
      "tensor([[-0.1711,  0.0129]])\n",
      "tensor([[0.0876, 0.0396]])\n",
      "tensor([[-0.0592, -0.0603]])\n",
      "tensor([[0.0218, 0.0471]])\n",
      "tensor([[-0.0015, -0.1121]])\n",
      "tensor([[-0.0129, -0.0083]])\n",
      "tensor([[0.1328, 0.0422]])\n",
      "tensor([[-0.0201,  0.0337]])\n",
      "tensor([[-0.0466, -0.0274]])\n",
      "tensor([[ 0.0907, -0.0087]])\n",
      "tensor([[ 0.1091, -0.0066]])\n",
      "tensor([[0.0117, 0.1367]])\n",
      "tensor([[ 0.0469, -0.0460]])\n",
      "tensor([[0.0400, 0.0133]])\n",
      "tensor([[-0.0270,  0.0599]])\n",
      "epoch: 53 , loss: 0.009695909917354584\n",
      "tensor([[0.0137, 0.1309]])\n",
      "tensor([[-0.0754, -0.0547]])\n",
      "tensor([[0.0921, 0.0234]])\n",
      "tensor([[-0.0518, -0.0009]])\n",
      "tensor([[-0.2055,  0.1944]])\n",
      "tensor([[-0.0201, -0.0202]])\n",
      "tensor([[-0.0030,  0.0241]])\n",
      "tensor([[ 0.1284, -0.0164]])\n",
      "tensor([[ 0.0322, -0.0476]])\n",
      "tensor([[-0.0071, -0.0476]])\n",
      "tensor([[-0.0460, -0.0545]])\n",
      "tensor([[-0.0084, -0.0507]])\n",
      "tensor([[ 0.0272, -0.0324]])\n",
      "tensor([[-0.0827, -0.1242]])\n",
      "tensor([[ 0.1120, -0.0118]])\n",
      "tensor([[-0.0077,  0.0040]])\n",
      "tensor([[ 0.0113, -0.0210]])\n",
      "tensor([[0.0915, 0.1931]])\n",
      "tensor([[ 0.0563, -0.0766]])\n",
      "tensor([[-0.0403, -0.0567]])\n",
      "epoch: 54 , loss: 0.010129861533641815\n",
      "tensor([[0.0194, 0.0337]])\n",
      "tensor([[-0.0595, -0.0462]])\n",
      "tensor([[-0.0820,  0.0183]])\n",
      "tensor([[0.0086, 0.0239]])\n",
      "tensor([[0.0253, 0.0030]])\n",
      "tensor([[0.0296, 0.0188]])\n",
      "tensor([[ 0.0671, -0.0392]])\n",
      "tensor([[0.0114, 0.0712]])\n",
      "tensor([[ 0.0577, -0.0778]])\n",
      "tensor([[-0.0850,  0.1719]])\n",
      "tensor([[0.1020, 0.0679]])\n",
      "tensor([[-0.0315, -0.0968]])\n",
      "tensor([[ 0.1535, -0.0134]])\n",
      "tensor([[-0.0553, -0.0313]])\n",
      "tensor([[-0.0298, -0.0424]])\n",
      "tensor([[-0.0309,  0.0434]])\n",
      "tensor([[-0.0817, -0.0167]])\n",
      "tensor([[0.0368, 0.0082]])\n",
      "tensor([[-0.1446, -0.0873]])\n",
      "tensor([[ 0.0416, -0.0351]])\n",
      "epoch: 55 , loss: 0.008132264018058777\n",
      "tensor([[-0.0746, -0.0094]])\n",
      "tensor([[-0.0007,  0.0509]])\n",
      "tensor([[-0.0059, -0.0372]])\n",
      "tensor([[0.0400, 0.0309]])\n",
      "tensor([[ 0.1486, -0.0785]])\n",
      "tensor([[-0.0603,  0.0008]])\n",
      "tensor([[-0.0712, -0.0231]])\n",
      "tensor([[ 0.0753, -0.0301]])\n",
      "tensor([[-0.0912, -0.1000]])\n",
      "tensor([[-0.0308,  0.0763]])\n",
      "tensor([[0.0063, 0.0037]])\n",
      "tensor([[-0.0089, -0.0622]])\n",
      "tensor([[0.0243, 0.0144]])\n",
      "tensor([[0.1010, 0.1123]])\n",
      "tensor([[-0.0556,  0.0093]])\n",
      "tensor([[0.0456, 0.0086]])\n",
      "tensor([[-0.0662,  0.0930]])\n",
      "tensor([[ 0.0199, -0.1719]])\n",
      "tensor([[0.0276, 0.0476]])\n",
      "tensor([[-0.0382,  0.1091]])\n",
      "epoch: 56 , loss: 0.01578109711408615\n",
      "tensor([[0.1090, 0.0257]])\n",
      "tensor([[-0.0637,  0.0824]])\n",
      "tensor([[ 0.1148, -0.0793]])\n",
      "tensor([[ 0.0336, -0.0343]])\n",
      "tensor([[0.0544, 0.0376]])\n",
      "tensor([[ 0.1045, -0.0864]])\n",
      "tensor([[-0.0764, -0.0793]])\n",
      "tensor([[-0.0164,  0.0013]])\n",
      "tensor([[-0.0071, -0.0030]])\n",
      "tensor([[-0.0651, -0.0540]])\n",
      "tensor([[0.0453, 0.0123]])\n",
      "tensor([[0.0014, 0.0677]])\n",
      "tensor([[-0.0490, -0.0284]])\n",
      "tensor([[-0.1430,  0.0202]])\n",
      "tensor([[-0.0003,  0.0309]])\n",
      "tensor([[0.0125, 0.0308]])\n",
      "tensor([[-0.0884, -0.1011]])\n",
      "tensor([[0.0017, 0.1634]])\n",
      "tensor([[ 0.0149, -0.0151]])\n",
      "tensor([[-0.0573,  0.0336]])\n",
      "epoch: 57 , loss: 0.008621652610599995\n",
      "tensor([[0.1255, 0.0824]])\n",
      "tensor([[-0.1195, -0.0541]])\n",
      "tensor([[ 0.0136, -0.1014]])\n",
      "tensor([[ 0.0133, -0.0199]])\n",
      "tensor([[ 0.1086, -0.0211]])\n",
      "tensor([[ 0.0097, -0.0553]])\n",
      "tensor([[-0.0120,  0.0734]])\n",
      "tensor([[-0.0954, -0.0431]])\n",
      "tensor([[ 0.0164, -0.0066]])\n",
      "tensor([[0.0542, 0.0381]])\n",
      "tensor([[0.0036, 0.0495]])\n",
      "tensor([[-0.0588, -0.0708]])\n",
      "tensor([[-0.0445,  0.0468]])\n",
      "tensor([[-0.0095,  0.0022]])\n",
      "tensor([[-0.0124, -0.0175]])\n",
      "tensor([[0.0413, 0.0945]])\n",
      "tensor([[-0.0243, -0.0030]])\n",
      "tensor([[0.0426, 0.1179]])\n",
      "tensor([[-0.0987, -0.0701]])\n",
      "tensor([[ 0.0493, -0.0259]])\n",
      "epoch: 58 , loss: 0.0059153009206056595\n",
      "tensor([[-0.0493, -0.0301]])\n",
      "tensor([[-0.0101, -0.0075]])\n",
      "tensor([[-0.0022,  0.0267]])\n",
      "tensor([[ 0.0386, -0.0678]])\n",
      "tensor([[ 0.0268, -0.0591]])\n",
      "tensor([[0.1363, 0.0494]])\n",
      "tensor([[-0.0780, -0.0912]])\n",
      "tensor([[-0.1323,  0.0094]])\n",
      "tensor([[0.1214, 0.0469]])\n",
      "tensor([[-0.0119,  0.0269]])\n",
      "tensor([[-0.0081,  0.0029]])\n",
      "tensor([[0.0196, 0.1545]])\n",
      "tensor([[-0.0121, -0.0603]])\n",
      "tensor([[ 0.0489, -0.0555]])\n",
      "tensor([[ 0.0194, -0.0371]])\n",
      "tensor([[-0.0429,  0.0893]])\n",
      "tensor([[-0.0290, -0.0535]])\n",
      "tensor([[0.0784, 0.0370]])\n",
      "tensor([[-0.0753,  0.0944]])\n",
      "tensor([[-0.0273, -0.0673]])\n",
      "epoch: 59 , loss: 0.005443993024528027\n",
      "tensor([[0.0114, 0.0788]])\n",
      "tensor([[ 0.0651, -0.0538]])\n",
      "tensor([[0.0853, 0.0560]])\n",
      "tensor([[0.0216, 0.0279]])\n",
      "tensor([[ 0.0013, -0.0032]])\n",
      "tensor([[ 0.1496, -0.0499]])\n",
      "tensor([[-0.0681, -0.0698]])\n",
      "tensor([[0.0871, 0.0991]])\n",
      "tensor([[4.2181e-02, 3.4009e-05]])\n",
      "tensor([[-0.0686, -0.0423]])\n",
      "tensor([[ 0.0062, -0.0376]])\n",
      "tensor([[-0.0689, -0.0548]])\n",
      "tensor([[-0.0164,  0.1318]])\n",
      "tensor([[-0.0884, -0.0317]])\n",
      "tensor([[0.0250, 0.0072]])\n",
      "tensor([[-0.1278, -0.0205]])\n",
      "tensor([[-0.0350, -0.0918]])\n",
      "tensor([[-0.0816,  0.0401]])\n",
      "tensor([[-0.0349, -0.0036]])\n",
      "tensor([[ 0.0304, -0.0133]])\n",
      "epoch: 60 , loss: 0.009974374435842037\n",
      "tensor([[0.0727, 0.0237]])\n",
      "tensor([[ 0.0481, -0.0268]])\n",
      "tensor([[ 0.0352, -0.0184]])\n",
      "tensor([[ 0.0607, -0.0177]])\n",
      "tensor([[0.0747, 0.0187]])\n",
      "tensor([[ 0.1076, -0.0007]])\n",
      "tensor([[0.0342, 0.1363]])\n",
      "tensor([[-0.0872, -0.0738]])\n",
      "tensor([[-0.1419, -0.0312]])\n",
      "tensor([[0.0899, 0.0758]])\n",
      "tensor([[-0.0968, -0.0790]])\n",
      "tensor([[ 0.0613, -0.0618]])\n",
      "tensor([[-0.1336, -0.0406]])\n",
      "tensor([[-0.0094, -0.0911]])\n",
      "tensor([[-0.0564,  0.1400]])\n",
      "tensor([[-0.0412, -0.0132]])\n",
      "tensor([[-0.0103,  0.0076]])\n",
      "tensor([[-0.0098,  0.0041]])\n",
      "tensor([[0.0211, 0.0551]])\n",
      "tensor([[-0.0547, -0.0090]])\n",
      "epoch: 61 , loss: 0.006231600418686867\n",
      "tensor([[0.0198, 0.0325]])\n",
      "tensor([[-0.1216, -0.0729]])\n",
      "tensor([[0.0583, 0.0292]])\n",
      "tensor([[0.0624, 0.0040]])\n",
      "tensor([[ 0.0962, -0.0464]])\n",
      "tensor([[-0.0252, -0.0481]])\n",
      "tensor([[0.0158, 0.0488]])\n",
      "tensor([[-0.0296, -0.0254]])\n",
      "tensor([[ 0.1138, -0.0068]])\n",
      "tensor([[-0.0784,  0.0450]])\n",
      "tensor([[-0.0253,  0.0173]])\n",
      "tensor([[-0.0269,  0.0483]])\n",
      "tensor([[ 0.0262, -0.0105]])\n",
      "tensor([[-0.0062, -0.0979]])\n",
      "tensor([[0.0465, 0.0389]])\n",
      "tensor([[ 0.0041, -0.1019]])\n",
      "tensor([[-0.1497,  0.1152]])\n",
      "tensor([[ 0.0461, -0.0195]])\n",
      "tensor([[0.0632, 0.0476]])\n",
      "tensor([[-0.0559,  0.0140]])\n",
      "epoch: 62 , loss: 0.006357401609420776\n",
      "tensor([[-0.0457, -0.0180]])\n",
      "tensor([[-0.0118, -0.0002]])\n",
      "tensor([[0.0571, 0.1667]])\n",
      "tensor([[-0.0069,  0.0284]])\n",
      "tensor([[-0.0008,  0.0098]])\n",
      "tensor([[ 0.0937, -0.0531]])\n",
      "tensor([[ 0.0017, -0.0896]])\n",
      "tensor([[0.0028, 0.0684]])\n",
      "tensor([[-0.1354, -0.0990]])\n",
      "tensor([[-0.0873, -0.0998]])\n",
      "tensor([[0.0036, 0.0677]])\n",
      "tensor([[0.0997, 0.1042]])\n",
      "tensor([[-0.0615,  0.0273]])\n",
      "tensor([[-0.0182,  0.0078]])\n",
      "tensor([[-0.0909,  0.0311]])\n",
      "tensor([[-0.0461, -0.0701]])\n",
      "tensor([[ 0.2346, -0.0067]])\n",
      "tensor([[-0.0009,  0.0111]])\n",
      "tensor([[ 0.0013, -0.0861]])\n",
      "tensor([[ 0.0717, -0.0231]])\n",
      "epoch: 63 , loss: 0.011212115176022053\n",
      "tensor([[ 0.0538, -0.0053]])\n",
      "tensor([[-0.0174,  0.1345]])\n",
      "tensor([[-0.0060,  0.0343]])\n",
      "tensor([[-0.0375, -0.0685]])\n",
      "tensor([[ 0.0412, -0.2308]])\n",
      "tensor([[-0.0267, -0.0571]])\n",
      "tensor([[0.0316, 0.0150]])\n",
      "tensor([[-0.1076, -0.0078]])\n",
      "tensor([[-0.0490, -0.0052]])\n",
      "tensor([[0.0198, 0.0238]])\n",
      "tensor([[-0.0108, -0.1456]])\n",
      "tensor([[ 0.0194, -0.0679]])\n",
      "tensor([[0.0047, 0.0423]])\n",
      "tensor([[-0.0425,  0.0113]])\n",
      "tensor([[0.0965, 0.0911]])\n",
      "tensor([[0.0860, 0.1573]])\n",
      "tensor([[0.0032, 0.0364]])\n",
      "tensor([[-0.0437,  0.0762]])\n",
      "tensor([[ 0.0467, -0.0105]])\n",
      "tensor([[-0.0208,  0.0317]])\n",
      "epoch: 64 , loss: 0.007324243430048227\n",
      "tensor([[0.0075, 0.0125]])\n",
      "tensor([[ 0.1651, -0.0564]])\n",
      "tensor([[0.0256, 0.0059]])\n",
      "tensor([[-0.0967,  0.0413]])\n",
      "tensor([[-0.1009,  0.0292]])\n",
      "tensor([[-0.1153, -0.0645]])\n",
      "tensor([[0.1645, 0.1262]])\n",
      "tensor([[-0.0342,  0.0586]])\n",
      "tensor([[-0.0023, -0.0192]])\n",
      "tensor([[-0.0579,  0.0434]])\n",
      "tensor([[-0.0089, -0.0259]])\n",
      "tensor([[ 0.0095, -0.0440]])\n",
      "tensor([[-0.0914,  0.0901]])\n",
      "tensor([[-0.0897, -0.1297]])\n",
      "tensor([[0.0334, 0.0038]])\n",
      "tensor([[-0.0105, -0.0035]])\n",
      "tensor([[-0.0095, -0.0559]])\n",
      "tensor([[ 0.1366, -0.0587]])\n",
      "tensor([[-0.0029,  0.0124]])\n",
      "tensor([[ 0.0988, -0.0102]])\n",
      "epoch: 65 , loss: 0.008701720274984837\n",
      "tensor([[0.0800, 0.0486]])\n",
      "tensor([[ 0.0264, -0.0503]])\n",
      "tensor([[0.0111, 0.0900]])\n",
      "tensor([[ 0.0017, -0.0792]])\n",
      "tensor([[ 0.0331, -0.1191]])\n",
      "tensor([[-0.1122,  0.0064]])\n",
      "tensor([[-0.0513, -0.0961]])\n",
      "tensor([[-0.0153,  0.1097]])\n",
      "tensor([[-0.0128,  0.0386]])\n",
      "tensor([[-0.0362,  0.0291]])\n",
      "tensor([[0.0849, 0.0824]])\n",
      "tensor([[0.1079, 0.0581]])\n",
      "tensor([[0.0361, 0.0187]])\n",
      "tensor([[ 0.0469, -0.0432]])\n",
      "tensor([[-0.0262, -0.0470]])\n",
      "tensor([[-0.0800,  0.0045]])\n",
      "tensor([[-0.0316, -0.0209]])\n",
      "tensor([[ 0.0211, -0.0382]])\n",
      "tensor([[-0.0809, -0.0029]])\n",
      "tensor([[-0.0381,  0.0054]])\n",
      "epoch: 66 , loss: 0.008011399768292904\n",
      "tensor([[-0.0118, -0.1119]])\n",
      "tensor([[0.0761, 0.0773]])\n",
      "tensor([[0.0025, 0.0111]])\n",
      "tensor([[-0.0701, -0.0421]])\n",
      "tensor([[ 0.0623, -0.0060]])\n",
      "tensor([[1.5974e-02, 4.6676e-05]])\n",
      "tensor([[ 0.1016, -0.1281]])\n",
      "tensor([[-0.0245, -0.0204]])\n",
      "tensor([[ 0.0832, -0.0428]])\n",
      "tensor([[0.0709, 0.1703]])\n",
      "tensor([[-0.1922,  0.0832]])\n",
      "tensor([[0.0188, 0.0466]])\n",
      "tensor([[-0.1328, -0.0564]])\n",
      "tensor([[-0.0537,  0.0079]])\n",
      "tensor([[-0.0326, -0.0615]])\n",
      "tensor([[0.1261, 0.0687]])\n",
      "tensor([[-0.0032,  0.0307]])\n",
      "tensor([[ 0.0282, -0.0096]])\n",
      "tensor([[-0.0278, -0.0116]])\n",
      "tensor([[-0.0556,  0.0161]])\n",
      "epoch: 67 , loss: 0.010477263480424881\n",
      "tensor([[ 0.0203, -0.0087]])\n",
      "tensor([[ 0.0268, -0.0245]])\n",
      "tensor([[-0.0560,  0.1058]])\n",
      "tensor([[0.0693, 0.0237]])\n",
      "tensor([[-0.0242,  0.0353]])\n",
      "tensor([[0.0848, 0.0611]])\n",
      "tensor([[0.0241, 0.0833]])\n",
      "tensor([[0.0143, 0.0040]])\n",
      "tensor([[-0.0435, -0.1239]])\n",
      "tensor([[0.0177, 0.0113]])\n",
      "tensor([[ 0.0090, -0.0505]])\n",
      "tensor([[0.0042, 0.0002]])\n",
      "tensor([[-0.0684, -0.0198]])\n",
      "tensor([[-0.0499,  0.0878]])\n",
      "tensor([[0.0294, 0.0413]])\n",
      "tensor([[-0.0020, -0.0778]])\n",
      "tensor([[-0.0902, -0.1678]])\n",
      "tensor([[0.0868, 0.1637]])\n",
      "tensor([[-0.0975, -0.1244]])\n",
      "tensor([[ 0.0290, -0.0780]])\n",
      "epoch: 68 , loss: 0.009748139418661594\n",
      "tensor([[-0.0044, -0.0833]])\n",
      "tensor([[0.0828, 0.0059]])\n",
      "tensor([[ 0.0992, -0.0352]])\n",
      "tensor([[-0.0778, -0.0837]])\n",
      "tensor([[0.1169, 0.0277]])\n",
      "tensor([[-0.0143,  0.0279]])\n",
      "tensor([[-0.1415,  0.0292]])\n",
      "tensor([[-0.0145,  0.1063]])\n",
      "tensor([[0.0602, 0.0305]])\n",
      "tensor([[-0.1733,  0.0042]])\n",
      "tensor([[-0.0154, -0.0299]])\n",
      "tensor([[ 0.0545, -0.0329]])\n",
      "tensor([[ 0.0372, -0.0016]])\n",
      "tensor([[0.0134, 0.0259]])\n",
      "tensor([[-0.0066,  0.0549]])\n",
      "tensor([[-0.1461, -0.0993]])\n",
      "tensor([[0.1298, 0.0901]])\n",
      "tensor([[ 0.0112, -0.0592]])\n",
      "tensor([[0.0034, 0.0276]])\n",
      "tensor([[-0.0085,  0.0243]])\n",
      "epoch: 69 , loss: 0.0034152213484048843\n",
      "tensor([[ 0.0808, -0.0003]])\n",
      "tensor([[0.1011, 0.0037]])\n",
      "tensor([[-0.0604, -0.0488]])\n",
      "tensor([[ 0.1866, -0.1176]])\n",
      "tensor([[-0.1589, -0.0599]])\n",
      "tensor([[-0.0603,  0.0192]])\n",
      "tensor([[-0.2088,  0.0575]])\n",
      "tensor([[0.0608, 0.0046]])\n",
      "tensor([[0.0315, 0.0482]])\n",
      "tensor([[-0.0478,  0.0400]])\n",
      "tensor([[-0.0872,  0.0102]])\n",
      "tensor([[ 0.0241, -0.0129]])\n",
      "tensor([[ 0.0546, -0.0139]])\n",
      "tensor([[ 0.0517, -0.0024]])\n",
      "tensor([[0.1344, 0.0992]])\n",
      "tensor([[-0.0192, -0.0949]])\n",
      "tensor([[-0.0388,  0.0466]])\n",
      "tensor([[0.0918, 0.0038]])\n",
      "tensor([[ 0.0033, -0.0206]])\n",
      "tensor([[-0.1311,  0.0691]])\n",
      "epoch: 70 , loss: 0.0057672495022416115\n",
      "tensor([[-0.0381, -0.0543]])\n",
      "tensor([[-0.1225, -0.0312]])\n",
      "tensor([[-0.0129,  0.0490]])\n",
      "tensor([[ 0.0106, -0.0288]])\n",
      "tensor([[-0.0267,  0.0237]])\n",
      "tensor([[ 0.0829, -0.0088]])\n",
      "tensor([[-0.0944,  0.0206]])\n",
      "tensor([[ 0.0541, -0.0343]])\n",
      "tensor([[-0.0632, -0.0514]])\n",
      "tensor([[ 0.0596, -0.0644]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0155, 0.0269]])\n",
      "tensor([[0.0957, 0.0449]])\n",
      "tensor([[0.0293, 0.0326]])\n",
      "tensor([[ 0.0028, -0.0112]])\n",
      "tensor([[ 0.0130, -0.0319]])\n",
      "tensor([[0.1267, 0.0677]])\n",
      "tensor([[-0.0169,  0.1136]])\n",
      "tensor([[-0.0344,  0.0321]])\n",
      "tensor([[-0.0184, -0.0922]])\n",
      "tensor([[-0.0027,  0.0163]])\n",
      "epoch: 71 , loss: 0.0032208245247602463\n",
      "tensor([[-0.0308, -0.0782]])\n",
      "tensor([[0.1150, 0.0129]])\n",
      "tensor([[-0.0461, -0.0063]])\n",
      "tensor([[-0.0299, -0.0441]])\n",
      "tensor([[-0.0153, -0.0131]])\n",
      "tensor([[0.0058, 0.0681]])\n",
      "tensor([[3.3452e-02, 8.3891e-05]])\n",
      "tensor([[-0.0740, -0.1380]])\n",
      "tensor([[ 0.0472, -0.0542]])\n",
      "tensor([[ 0.0113, -0.0457]])\n",
      "tensor([[0.0023, 0.1376]])\n",
      "tensor([[0.0724, 0.0009]])\n",
      "tensor([[-0.0348,  0.0913]])\n",
      "tensor([[-0.0152, -0.0541]])\n",
      "tensor([[-0.0238, -0.0265]])\n",
      "tensor([[-0.0402,  0.1362]])\n",
      "tensor([[0.0042, 0.0327]])\n",
      "tensor([[-0.0864,  0.0490]])\n",
      "tensor([[ 0.0265, -0.0116]])\n",
      "tensor([[ 0.0634, -0.0385]])\n",
      "epoch: 72 , loss: 0.004686727654188871\n",
      "tensor([[0.0624, 0.0258]])\n",
      "tensor([[0.0281, 0.0041]])\n",
      "tensor([[-0.0104, -0.0946]])\n",
      "tensor([[-0.1329, -0.0940]])\n",
      "tensor([[ 0.0741, -0.1127]])\n",
      "tensor([[ 0.0671, -0.0395]])\n",
      "tensor([[-0.0419,  0.0090]])\n",
      "tensor([[0.0002, 0.1030]])\n",
      "tensor([[0.0460, 0.0276]])\n",
      "tensor([[-0.0917,  0.0217]])\n",
      "tensor([[-0.0639,  0.0334]])\n",
      "tensor([[-0.0494, -0.0142]])\n",
      "tensor([[ 0.1179, -0.0290]])\n",
      "tensor([[ 0.0059, -0.0490]])\n",
      "tensor([[-0.0134,  0.0436]])\n",
      "tensor([[0.0146, 0.0151]])\n",
      "tensor([[-0.0047,  0.1377]])\n",
      "tensor([[-0.0119, -0.0376]])\n",
      "tensor([[ 0.0239, -0.0054]])\n",
      "tensor([[-0.0210,  0.0759]])\n",
      "epoch: 73 , loss: 0.012352945283055305\n",
      "tensor([[0.0012, 0.0090]])\n",
      "tensor([[-0.0652, -0.0385]])\n",
      "tensor([[-0.0072, -0.0515]])\n",
      "tensor([[0.0663, 0.0182]])\n",
      "tensor([[0.0712, 0.0382]])\n",
      "tensor([[-0.0070,  0.0692]])\n",
      "tensor([[-0.1166, -0.1192]])\n",
      "tensor([[ 0.0097, -0.0150]])\n",
      "tensor([[0.0279, 0.0383]])\n",
      "tensor([[0.0079, 0.0271]])\n",
      "tensor([[-0.0561, -0.0620]])\n",
      "tensor([[-0.1070,  0.0004]])\n",
      "tensor([[ 0.0281, -0.0465]])\n",
      "tensor([[ 0.0020, -0.1125]])\n",
      "tensor([[0.1062, 0.0679]])\n",
      "tensor([[-0.0070,  0.0101]])\n",
      "tensor([[0.0343, 0.0508]])\n",
      "tensor([[0.0228, 0.0128]])\n",
      "tensor([[-0.0104,  0.0008]])\n",
      "tensor([[0.0138, 0.0958]])\n",
      "epoch: 74 , loss: 0.01578032411634922\n",
      "tensor([[0.0244, 0.0206]])\n",
      "tensor([[ 0.0297, -0.0375]])\n",
      "tensor([[ 0.0419, -0.0118]])\n",
      "tensor([[ 0.0409, -0.0127]])\n",
      "tensor([[0.0886, 0.0860]])\n",
      "tensor([[-0.0165,  0.1350]])\n",
      "tensor([[ 0.0555, -0.0725]])\n",
      "tensor([[-0.0527, -0.0136]])\n",
      "tensor([[-0.0621, -0.0899]])\n",
      "tensor([[-0.0202,  0.0680]])\n",
      "tensor([[-0.0366,  0.0049]])\n",
      "tensor([[-0.0428,  0.1051]])\n",
      "tensor([[ 0.0335, -0.0451]])\n",
      "tensor([[ 0.0133, -0.0224]])\n",
      "tensor([[0.1308, 0.0358]])\n",
      "tensor([[-0.0467,  0.0530]])\n",
      "tensor([[ 0.0069, -0.0248]])\n",
      "tensor([[-0.1455, -0.0957]])\n",
      "tensor([[-0.0943, -0.1221]])\n",
      "tensor([[-0.0166, -0.0281]])\n",
      "epoch: 75 , loss: 0.011295861564576626\n",
      "tensor([[-0.0355, -0.1193]])\n",
      "tensor([[ 0.0185, -0.0434]])\n",
      "tensor([[0.0692, 0.0271]])\n",
      "tensor([[ 0.0452, -0.0592]])\n",
      "tensor([[ 0.0054, -0.0119]])\n",
      "tensor([[-0.1022,  0.0669]])\n",
      "tensor([[-0.1164, -0.0151]])\n",
      "tensor([[ 0.0092, -0.0276]])\n",
      "tensor([[0.1309, 0.0052]])\n",
      "tensor([[-0.0672, -0.0898]])\n",
      "tensor([[-0.0783,  0.0479]])\n",
      "tensor([[-0.0008,  0.0275]])\n",
      "tensor([[-0.0905, -0.0563]])\n",
      "tensor([[0.0365, 0.0463]])\n",
      "tensor([[-0.0801, -0.0875]])\n",
      "tensor([[ 0.0983, -0.0393]])\n",
      "tensor([[0.0025, 0.1758]])\n",
      "tensor([[0.0552, 0.0197]])\n",
      "tensor([[0.1337, 0.0885]])\n",
      "tensor([[0.0292, 0.1173]])\n",
      "epoch: 76 , loss: 0.0068260678090155125\n",
      "tensor([[0.0244, 0.1101]])\n",
      "tensor([[0.0178, 0.0615]])\n",
      "tensor([[-0.0473, -0.0735]])\n",
      "tensor([[-0.1132,  0.0155]])\n",
      "tensor([[-0.0756, -0.0185]])\n",
      "tensor([[0.0667, 0.0240]])\n",
      "tensor([[-0.1043, -0.0133]])\n",
      "tensor([[0.0176, 0.0025]])\n",
      "tensor([[-0.0921,  0.0245]])\n",
      "tensor([[-0.0603, -0.0405]])\n",
      "tensor([[-0.0284, -0.0561]])\n",
      "tensor([[-0.0654,  0.0326]])\n",
      "tensor([[ 0.0328, -0.0084]])\n",
      "tensor([[0.0861, 0.0707]])\n",
      "tensor([[ 0.0681, -0.1003]])\n",
      "tensor([[-0.0016, -0.0010]])\n",
      "tensor([[ 0.0252, -0.0144]])\n",
      "tensor([[ 0.1083, -0.0824]])\n",
      "tensor([[0.1079, 0.0292]])\n",
      "tensor([[ 0.1174, -0.0091]])\n",
      "epoch: 77 , loss: 0.0076510608196258545\n",
      "tensor([[-0.0245,  0.0619]])\n",
      "tensor([[-0.0418, -0.0220]])\n",
      "tensor([[ 0.0783, -0.0506]])\n",
      "tensor([[ 0.0220, -0.0005]])\n",
      "tensor([[ 0.0627, -0.0221]])\n",
      "tensor([[0.0622, 0.0886]])\n",
      "tensor([[-0.0505,  0.0721]])\n",
      "tensor([[ 0.0851, -0.0020]])\n",
      "tensor([[-0.0474,  0.0575]])\n",
      "tensor([[ 0.1203, -0.1574]])\n",
      "tensor([[-0.1161,  0.1266]])\n",
      "tensor([[0.0619, 0.0276]])\n",
      "tensor([[-0.0436, -0.0351]])\n",
      "tensor([[-0.0205, -0.0264]])\n",
      "tensor([[ 0.0748, -0.0471]])\n",
      "tensor([[-0.0796, -0.0469]])\n",
      "tensor([[-0.0100,  0.0195]])\n",
      "tensor([[-0.0852, -0.0772]])\n",
      "tensor([[-0.1195,  0.0492]])\n",
      "tensor([[-0.0259, -0.0605]])\n",
      "epoch: 78 , loss: 0.013262970373034477\n",
      "tensor([[0.0993, 0.0251]])\n",
      "tensor([[-0.0162, -0.0336]])\n",
      "tensor([[0.0426, 0.0611]])\n",
      "tensor([[0.0373, 0.0592]])\n",
      "tensor([[-0.0653,  0.0355]])\n",
      "tensor([[-0.0259, -0.1028]])\n",
      "tensor([[-0.0229,  0.0203]])\n",
      "tensor([[ 0.1320, -0.0678]])\n",
      "tensor([[ 0.0342, -0.0038]])\n",
      "tensor([[ 0.0690, -0.0352]])\n",
      "tensor([[0.0040, 0.0518]])\n",
      "tensor([[-0.0353,  0.0689]])\n",
      "tensor([[0.0170, 0.0444]])\n",
      "tensor([[-0.1318, -0.0517]])\n",
      "tensor([[-0.0255,  0.0195]])\n",
      "tensor([[ 0.0310, -0.0408]])\n",
      "tensor([[-0.0415, -0.0172]])\n",
      "tensor([[-0.1519, -0.1422]])\n",
      "tensor([[-0.0315,  0.0044]])\n",
      "tensor([[0.0195, 0.0925]])\n",
      "epoch: 79 , loss: 0.01632711850106716\n",
      "tensor([[-0.0372, -0.0783]])\n",
      "tensor([[ 0.0439, -0.0294]])\n",
      "tensor([[ 0.0769, -0.1092]])\n",
      "tensor([[-0.0130, -0.0283]])\n",
      "tensor([[-0.0618,  0.0022]])\n",
      "tensor([[-0.0724,  0.0931]])\n",
      "tensor([[0.0987, 0.0688]])\n",
      "tensor([[0.0318, 0.0421]])\n",
      "tensor([[0.0009, 0.0127]])\n",
      "tensor([[-0.0392, -0.1456]])\n",
      "tensor([[ 0.0101, -0.0157]])\n",
      "tensor([[0.0455, 0.0631]])\n",
      "tensor([[-0.0560,  0.0014]])\n",
      "tensor([[0.0469, 0.0277]])\n",
      "tensor([[-0.0148, -0.0619]])\n",
      "tensor([[0.0763, 0.1607]])\n",
      "tensor([[0.0137, 0.0919]])\n",
      "tensor([[-0.1141, -0.0971]])\n",
      "tensor([[-0.0639,  0.0154]])\n",
      "tensor([[0.0441, 0.0237]])\n",
      "epoch: 80 , loss: 0.00939442589879036\n",
      "tensor([[-0.0971, -0.0549]])\n",
      "tensor([[ 0.0050, -0.0021]])\n",
      "tensor([[0.1400, 0.0453]])\n",
      "tensor([[-0.0308,  0.0874]])\n",
      "tensor([[-0.0833, -0.0024]])\n",
      "tensor([[-0.1041, -0.1371]])\n",
      "tensor([[0.0598, 0.0224]])\n",
      "tensor([[-0.0235,  0.0412]])\n",
      "tensor([[ 0.0440, -0.0697]])\n",
      "tensor([[-0.0530, -0.0032]])\n",
      "tensor([[-0.1047, -0.0164]])\n",
      "tensor([[0.0088, 0.1793]])\n",
      "tensor([[0.0696, 0.0295]])\n",
      "tensor([[ 0.0744, -0.0288]])\n",
      "tensor([[0.1017, 0.0329]])\n",
      "tensor([[ 0.0760, -0.0885]])\n",
      "tensor([[0.0229, 0.0316]])\n",
      "tensor([[-0.0682, -0.0607]])\n",
      "tensor([[0.0013, 0.0196]])\n",
      "tensor([[ 0.0021, -0.0401]])\n",
      "epoch: 81 , loss: 0.013251902535557747\n",
      "tensor([[0.0495, 0.0036]])\n",
      "tensor([[ 0.0699, -0.0258]])\n",
      "tensor([[0.0288, 0.0022]])\n",
      "tensor([[0.0406, 0.0143]])\n",
      "tensor([[-0.1269, -0.0579]])\n",
      "tensor([[-0.0334, -0.0224]])\n",
      "tensor([[-0.0597, -0.0480]])\n",
      "tensor([[ 0.0129, -0.0490]])\n",
      "tensor([[0.0322, 0.0307]])\n",
      "tensor([[ 0.0457, -0.0437]])\n",
      "tensor([[-0.0208,  0.1347]])\n",
      "tensor([[0.0648, 0.1211]])\n",
      "tensor([[-0.0980, -0.0538]])\n",
      "tensor([[-0.1063, -0.0022]])\n",
      "tensor([[ 0.0003, -0.0375]])\n",
      "tensor([[0.0358, 0.0612]])\n",
      "tensor([[0.0782, 0.0155]])\n",
      "tensor([[ 0.0899, -0.1013]])\n",
      "tensor([[-0.0311, -0.0615]])\n",
      "tensor([[-0.0888,  0.1332]])\n",
      "epoch: 82 , loss: 0.019399220123887062\n",
      "tensor([[ 0.0445, -0.0284]])\n",
      "tensor([[-0.0493, -0.0351]])\n",
      "tensor([[0.0621, 0.0484]])\n",
      "tensor([[0.0088, 0.0001]])\n",
      "tensor([[-0.0193,  0.0754]])\n",
      "tensor([[-0.0596, -0.1157]])\n",
      "tensor([[-0.0104, -0.0092]])\n",
      "tensor([[-0.0189, -0.0137]])\n",
      "tensor([[-0.0188,  0.1554]])\n",
      "tensor([[-0.0014, -0.0102]])\n",
      "tensor([[ 0.0109, -0.0130]])\n",
      "tensor([[-0.0579,  0.0263]])\n",
      "tensor([[0.1750, 0.0294]])\n",
      "tensor([[0.0319, 0.0132]])\n",
      "tensor([[-0.0013, -0.0278]])\n",
      "tensor([[-0.0236, -0.0698]])\n",
      "tensor([[ 0.0319, -0.0194]])\n",
      "tensor([[ 0.0274, -0.1414]])\n",
      "tensor([[-0.0701,  0.0763]])\n",
      "tensor([[-0.0569,  0.0520]])\n",
      "epoch: 83 , loss: 0.012362534180283546\n",
      "tensor([[-0.0126,  0.1286]])\n",
      "tensor([[0.1133, 0.0040]])\n",
      "tensor([[ 0.1151, -0.0302]])\n",
      "tensor([[-0.0191, -0.0461]])\n",
      "tensor([[-0.0331,  0.0513]])\n",
      "tensor([[-0.1021, -0.0070]])\n",
      "tensor([[-0.0264,  0.0425]])\n",
      "tensor([[0.1031, 0.0705]])\n",
      "tensor([[ 0.0637, -0.0424]])\n",
      "tensor([[-0.0517, -0.0386]])\n",
      "tensor([[-0.0390,  0.0759]])\n",
      "tensor([[ 0.0737, -0.0007]])\n",
      "tensor([[0.0195, 0.0309]])\n",
      "tensor([[ 0.0119, -0.0171]])\n",
      "tensor([[-0.1024, -0.0104]])\n",
      "tensor([[-0.1222, -0.0485]])\n",
      "tensor([[-0.1154, -0.0733]])\n",
      "tensor([[ 0.0317, -0.1019]])\n",
      "tensor([[-0.0166, -0.0217]])\n",
      "tensor([[ 0.0654, -0.0194]])\n",
      "epoch: 84 , loss: 0.005700908601284027\n",
      "tensor([[-0.0024,  0.0193]])\n",
      "tensor([[0.0304, 0.0316]])\n",
      "tensor([[ 0.0055, -0.0280]])\n",
      "tensor([[-0.0208,  0.0152]])\n",
      "tensor([[-0.1408,  0.0729]])\n",
      "tensor([[-0.0117,  0.0306]])\n",
      "tensor([[ 0.0137, -0.0224]])\n",
      "tensor([[-0.0536,  0.0075]])\n",
      "tensor([[ 0.0989, -0.0804]])\n",
      "tensor([[ 0.0487, -0.1036]])\n",
      "tensor([[-0.1171,  0.0513]])\n",
      "tensor([[-0.0257,  0.0274]])\n",
      "tensor([[ 0.1370, -0.0352]])\n",
      "tensor([[0.0755, 0.0085]])\n",
      "tensor([[0.0152, 0.0289]])\n",
      "tensor([[ 0.0036, -0.0209]])\n",
      "tensor([[-0.0116,  0.0027]])\n",
      "tensor([[-0.0157,  0.0705]])\n",
      "tensor([[-0.0468, -0.0708]])\n",
      "tensor([[ 0.0490, -0.0040]])\n",
      "epoch: 85 , loss: 0.005682240705937147\n",
      "tensor([[0.0166, 0.0222]])\n",
      "tensor([[0.0233, 0.0110]])\n",
      "tensor([[0.0833, 0.0059]])\n",
      "tensor([[ 0.0311, -0.0846]])\n",
      "tensor([[-0.0388, -0.0380]])\n",
      "tensor([[0.0692, 0.0876]])\n",
      "tensor([[0.0115, 0.1208]])\n",
      "tensor([[-0.0087, -0.0027]])\n",
      "tensor([[0.0454, 0.0819]])\n",
      "tensor([[0.0001, 0.0487]])\n",
      "tensor([[ 0.0154, -0.0297]])\n",
      "tensor([[-0.0495,  0.0027]])\n",
      "tensor([[-0.0449, -0.0999]])\n",
      "tensor([[-0.0047, -0.0141]])\n",
      "tensor([[-0.0874, -0.0202]])\n",
      "tensor([[0.0967, 0.0333]])\n",
      "tensor([[-0.1205, -0.0579]])\n",
      "tensor([[-0.0555,  0.0214]])\n",
      "tensor([[-0.0382, -0.0986]])\n",
      "tensor([[ 0.0036, -0.0190]])\n",
      "epoch: 86 , loss: 0.009683470241725445\n",
      "tensor([[-0.0428,  0.0196]])\n",
      "tensor([[ 0.0253, -0.0485]])\n",
      "tensor([[-0.0545, -0.0182]])\n",
      "tensor([[ 0.0491, -0.0134]])\n",
      "tensor([[0.0447, 0.0546]])\n",
      "tensor([[-0.0606, -0.0361]])\n",
      "tensor([[ 0.0649, -0.0102]])\n",
      "tensor([[-0.0787,  0.0433]])\n",
      "tensor([[0.0190, 0.0679]])\n",
      "tensor([[ 0.0221, -0.0495]])\n",
      "tensor([[-0.0331, -0.0027]])\n",
      "tensor([[-0.0506, -0.0403]])\n",
      "tensor([[-0.0996,  0.1222]])\n",
      "tensor([[ 0.0997, -0.1518]])\n",
      "tensor([[ 0.0395, -0.0448]])\n",
      "tensor([[0.0206, 0.0100]])\n",
      "tensor([[-0.0515,  0.0615]])\n",
      "tensor([[0.0043, 0.0573]])\n",
      "tensor([[ 0.0895, -0.0900]])\n",
      "tensor([[0.0468, 0.1108]])\n",
      "epoch: 87 , loss: 0.009648519568145275\n",
      "tensor([[-0.0354, -0.0504]])\n",
      "tensor([[0.0360, 0.0383]])\n",
      "tensor([[-0.0813, -0.0266]])\n",
      "tensor([[-0.0424, -0.0613]])\n",
      "tensor([[-0.0070,  0.0531]])\n",
      "tensor([[-0.0448, -0.1098]])\n",
      "tensor([[ 0.0637, -0.0953]])\n",
      "tensor([[-0.0130,  0.0937]])\n",
      "tensor([[0.0744, 0.0493]])\n",
      "tensor([[0.0264, 0.0327]])\n",
      "tensor([[-0.0614, -0.0309]])\n",
      "tensor([[ 0.0296, -0.0812]])\n",
      "tensor([[-0.1434, -0.0425]])\n",
      "tensor([[-0.0191,  0.0405]])\n",
      "tensor([[0.0653, 0.0111]])\n",
      "tensor([[ 0.0557, -0.0180]])\n",
      "tensor([[-0.0219,  0.0332]])\n",
      "tensor([[0.1754, 0.1238]])\n",
      "tensor([[-0.0715,  0.0676]])\n",
      "tensor([[0.0649, 0.0271]])\n",
      "epoch: 88 , loss: 0.00857517309486866\n",
      "tensor([[0.0095, 0.0016]])\n",
      "tensor([[0.1983, 0.1047]])\n",
      "tensor([[-0.0085, -0.0680]])\n",
      "tensor([[ 0.0841, -0.0209]])\n",
      "tensor([[0.0154, 0.0771]])\n",
      "tensor([[ 2.4386e-05, -6.2436e-02]])\n",
      "tensor([[0.0377, 0.0454]])\n",
      "tensor([[-0.0559, -0.0623]])\n",
      "tensor([[-0.0661, -0.0460]])\n",
      "tensor([[-0.1034,  0.0494]])\n",
      "tensor([[ 0.0725, -0.0104]])\n",
      "tensor([[-0.0470,  0.0258]])\n",
      "tensor([[ 0.0641, -0.0641]])\n",
      "tensor([[-0.0459,  0.0016]])\n",
      "tensor([[-0.0744, -0.0085]])\n",
      "tensor([[-0.0049,  0.0692]])\n",
      "tensor([[-0.0518,  0.0479]])\n",
      "tensor([[-0.0277,  0.0382]])\n",
      "tensor([[-0.0390, -0.0695]])\n",
      "tensor([[-0.0364, -0.0746]])\n",
      "epoch: 89 , loss: 0.012899748980998993\n",
      "tensor([[ 0.0247, -0.0819]])\n",
      "tensor([[ 0.0797, -0.0678]])\n",
      "tensor([[0.0640, 0.0916]])\n",
      "tensor([[-0.0320, -0.0137]])\n",
      "tensor([[-0.0246, -0.0051]])\n",
      "tensor([[0.1373, 0.0348]])\n",
      "tensor([[-0.0662, -0.0568]])\n",
      "tensor([[ 0.0454, -0.0489]])\n",
      "tensor([[ 0.0444, -0.0108]])\n",
      "tensor([[-0.0683,  0.0516]])\n",
      "tensor([[0.0537, 0.0779]])\n",
      "tensor([[0.0085, 0.0396]])\n",
      "tensor([[-0.1556,  0.0479]])\n",
      "tensor([[-0.0275, -0.0431]])\n",
      "tensor([[0.0035, 0.0137]])\n",
      "tensor([[-0.0394, -0.0891]])\n",
      "tensor([[0.0184, 0.0146]])\n",
      "tensor([[-0.0398,  0.0101]])\n",
      "tensor([[-0.0331,  0.0929]])\n",
      "tensor([[-0.0305, -0.0399]])\n",
      "epoch: 90 , loss: 0.007524325046688318\n",
      "tensor([[-0.1308, -0.0220]])\n",
      "tensor([[0.0603, 0.0900]])\n",
      "tensor([[ 0.0607, -0.0222]])\n",
      "tensor([[ 0.0855, -0.0716]])\n",
      "tensor([[0.0016, 0.0138]])\n",
      "tensor([[ 0.0278, -0.0345]])\n",
      "tensor([[ 0.0726, -0.0976]])\n",
      "tensor([[-0.0199,  0.0610]])\n",
      "tensor([[-0.0804,  0.0620]])\n",
      "tensor([[-0.0223,  0.0034]])\n",
      "tensor([[0.0159, 0.0038]])\n",
      "tensor([[ 0.1323, -0.0110]])\n",
      "tensor([[-0.0278,  0.0163]])\n",
      "tensor([[-5.5246e-03,  6.8598e-05]])\n",
      "tensor([[ 0.0195, -0.0184]])\n",
      "tensor([[-0.0583, -0.0161]])\n",
      "tensor([[ 0.0448, -0.0008]])\n",
      "tensor([[-0.1847,  0.0191]])\n",
      "tensor([[4.6985e-02, 5.8631e-05]])\n",
      "tensor([[-0.0337,  0.0244]])\n",
      "epoch: 91 , loss: 0.006761287339031696\n",
      "tensor([[-0.0470, -0.0059]])\n",
      "tensor([[-0.0629, -0.0398]])\n",
      "tensor([[-0.0022, -0.0098]])\n",
      "tensor([[0.0190, 0.0559]])\n",
      "tensor([[-0.0824,  0.0411]])\n",
      "tensor([[-0.0119,  0.1094]])\n",
      "tensor([[0.2009, 0.0006]])\n",
      "tensor([[ 0.0481, -0.0385]])\n",
      "tensor([[ 0.0085, -0.1076]])\n",
      "tensor([[-0.0198,  0.0811]])\n",
      "tensor([[0.0109, 0.0392]])\n",
      "tensor([[ 0.0171, -0.0397]])\n",
      "tensor([[-0.1432,  0.0196]])\n",
      "tensor([[-0.0054, -0.1309]])\n",
      "tensor([[-0.0045, -0.0966]])\n",
      "tensor([[0.0621, 0.0116]])\n",
      "tensor([[0.0481, 0.0271]])\n",
      "tensor([[-0.0494,  0.0186]])\n",
      "tensor([[ 0.0716, -0.0124]])\n",
      "tensor([[-0.0088,  0.0670]])\n",
      "epoch: 92 , loss: 0.0077617294155061245\n",
      "tensor([[0.0459, 0.0328]])\n",
      "tensor([[-0.0609, -0.0301]])\n",
      "tensor([[-0.0481, -0.1009]])\n",
      "tensor([[ 0.0698, -0.0042]])\n",
      "tensor([[ 0.0192, -0.0209]])\n",
      "tensor([[0.0199, 0.0239]])\n",
      "tensor([[-0.0700, -0.0582]])\n",
      "tensor([[ 0.0601, -0.0274]])\n",
      "tensor([[-0.0389, -0.0249]])\n",
      "tensor([[ 0.0036, -0.0706]])\n",
      "tensor([[0.0020, 0.1242]])\n",
      "tensor([[-0.0068, -0.0221]])\n",
      "tensor([[-0.0526,  0.0498]])\n",
      "tensor([[0.0711, 0.0133]])\n",
      "tensor([[0.0423, 0.0594]])\n",
      "tensor([[0.0540, 0.0475]])\n",
      "tensor([[-0.1086,  0.0845]])\n",
      "tensor([[0.0475, 0.0096]])\n",
      "tensor([[-0.0087, -0.0085]])\n",
      "tensor([[-0.0300, -0.0481]])\n",
      "epoch: 93 , loss: 0.00585514958947897\n",
      "tensor([[-0.1541, -0.0417]])\n",
      "tensor([[-0.0558, -0.0058]])\n",
      "tensor([[ 0.0126, -0.0656]])\n",
      "tensor([[-0.1167, -0.0684]])\n",
      "tensor([[-0.0461,  0.0402]])\n",
      "tensor([[-0.0122, -0.0120]])\n",
      "tensor([[ 0.0670, -0.0547]])\n",
      "tensor([[ 0.0620, -0.0414]])\n",
      "tensor([[ 0.0646, -0.0169]])\n",
      "tensor([[-0.0665,  0.0029]])\n",
      "tensor([[ 0.0682, -0.0048]])\n",
      "tensor([[0.0554, 0.0928]])\n",
      "tensor([[-0.0266, -0.0030]])\n",
      "tensor([[0.0190, 0.0702]])\n",
      "tensor([[ 0.0662, -0.0304]])\n",
      "tensor([[-0.0040,  0.0792]])\n",
      "tensor([[ 0.0994, -0.0742]])\n",
      "tensor([[-0.0260,  0.0279]])\n",
      "tensor([[0.0794, 0.0321]])\n",
      "tensor([[-0.0016,  0.1211]])\n",
      "epoch: 94 , loss: 0.014090923592448235\n",
      "tensor([[-0.0813,  0.0078]])\n",
      "tensor([[ 0.0860, -0.1100]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0106, -0.0572]])\n",
      "tensor([[ 0.0144, -0.0485]])\n",
      "tensor([[ 0.0311, -0.0194]])\n",
      "tensor([[-0.0604,  0.0242]])\n",
      "tensor([[ 0.1282, -0.0907]])\n",
      "tensor([[-0.0006,  0.0378]])\n",
      "tensor([[0.0588, 0.0660]])\n",
      "tensor([[-1.9008e-02, -1.3771e-05]])\n",
      "tensor([[-0.0383,  0.0353]])\n",
      "tensor([[-0.2250, -0.0252]])\n",
      "tensor([[-0.0161, -0.0008]])\n",
      "tensor([[ 0.0215, -0.0180]])\n",
      "tensor([[-0.0692,  0.0902]])\n",
      "tensor([[0.1121, 0.1180]])\n",
      "tensor([[-0.0670,  0.0708]])\n",
      "tensor([[ 0.0165, -0.1130]])\n",
      "tensor([[ 0.0106, -0.0012]])\n",
      "tensor([[0.0734, 0.0500]])\n",
      "epoch: 95 , loss: 0.008186906576156616\n",
      "tensor([[-0.0663, -0.0792]])\n",
      "tensor([[ 0.1053, -0.0095]])\n",
      "tensor([[-0.0266,  0.0211]])\n",
      "tensor([[0.0195, 0.0464]])\n",
      "tensor([[-0.0645,  0.0861]])\n",
      "tensor([[0.0009, 0.0290]])\n",
      "tensor([[0.0949, 0.0335]])\n",
      "tensor([[ 0.0099, -0.0618]])\n",
      "tensor([[0.0241, 0.0378]])\n",
      "tensor([[ 0.0103, -0.0143]])\n",
      "tensor([[-0.0182,  0.0436]])\n",
      "tensor([[-0.0124,  0.0756]])\n",
      "tensor([[0.0312, 0.0210]])\n",
      "tensor([[-0.1131, -0.0566]])\n",
      "tensor([[ 0.1180, -0.0538]])\n",
      "tensor([[-0.1153, -0.0436]])\n",
      "tensor([[ 0.0143, -0.0468]])\n",
      "tensor([[-0.0731, -0.0323]])\n",
      "tensor([[-0.0235, -0.0407]])\n",
      "tensor([[ 0.0431, -0.0251]])\n",
      "epoch: 96 , loss: 0.007650346960872412\n",
      "tensor([[0.0099, 0.0700]])\n",
      "tensor([[0.0027, 0.0140]])\n",
      "tensor([[-0.0165, -0.0248]])\n",
      "tensor([[-0.0073,  0.0068]])\n",
      "tensor([[0.0612, 0.0189]])\n",
      "tensor([[-0.0071, -0.1114]])\n",
      "tensor([[-0.0518, -0.0414]])\n",
      "tensor([[-0.0376,  0.0812]])\n",
      "tensor([[-0.0149,  0.0340]])\n",
      "tensor([[0.0207, 0.1421]])\n",
      "tensor([[ 0.0042, -0.0502]])\n",
      "tensor([[-0.0589, -0.0657]])\n",
      "tensor([[ 0.0278, -0.0877]])\n",
      "tensor([[-0.0165,  0.0136]])\n",
      "tensor([[0.0430, 0.0190]])\n",
      "tensor([[ 0.0110, -0.1310]])\n",
      "tensor([[0.0761, 0.1070]])\n",
      "tensor([[-0.0746, -0.0792]])\n",
      "tensor([[ 0.0401, -0.0021]])\n",
      "tensor([[-0.0044,  0.0620]])\n",
      "epoch: 97 , loss: 0.014246839098632336\n",
      "tensor([[ 0.0123, -0.0260]])\n",
      "tensor([[-0.1502,  0.0173]])\n",
      "tensor([[-0.1067, -0.0420]])\n",
      "tensor([[0.0353, 0.0603]])\n",
      "tensor([[0.0377, 0.2431]])\n",
      "tensor([[-0.0163, -0.1093]])\n",
      "tensor([[0.0946, 0.0650]])\n",
      "tensor([[-0.0195, -0.0418]])\n",
      "tensor([[-0.0322,  0.0220]])\n",
      "tensor([[-0.0378,  0.0113]])\n",
      "tensor([[-0.0262, -0.0596]])\n",
      "tensor([[0.1831, 0.0396]])\n",
      "tensor([[-0.0535, -0.1193]])\n",
      "tensor([[ 0.1460, -0.0247]])\n",
      "tensor([[ 0.0219, -0.0270]])\n",
      "tensor([[ 0.0283, -0.0393]])\n",
      "tensor([[-0.1147,  0.0809]])\n",
      "tensor([[ 0.0160, -0.0309]])\n",
      "tensor([[-0.0482, -0.0420]])\n",
      "tensor([[0.0526, 0.0010]])\n",
      "epoch: 98 , loss: 0.006924022920429707\n",
      "tensor([[-0.0944,  0.0069]])\n",
      "tensor([[-0.0261,  0.0913]])\n",
      "tensor([[0.1016, 0.0523]])\n",
      "tensor([[0.0172, 0.0647]])\n",
      "tensor([[-0.0678,  0.0514]])\n",
      "tensor([[0.0915, 0.0210]])\n",
      "tensor([[-0.0358,  0.0029]])\n",
      "tensor([[-0.1291, -0.1331]])\n",
      "tensor([[-0.0579,  0.1090]])\n",
      "tensor([[ 0.0335, -0.1393]])\n",
      "tensor([[0.0451, 0.0288]])\n",
      "tensor([[-0.0426, -0.0872]])\n",
      "tensor([[0.0853, 0.0113]])\n",
      "tensor([[0.1333, 0.0067]])\n",
      "tensor([[-0.0961, -0.0837]])\n",
      "tensor([[ 0.0756, -0.0168]])\n",
      "tensor([[-0.0303,  0.0334]])\n",
      "tensor([[-0.0316, -0.1068]])\n",
      "tensor([[-0.0120,  0.0474]])\n",
      "tensor([[ 0.0439, -0.0069]])\n",
      "epoch: 99 , loss: 0.004424307029694319\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epoch = 100\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "loss = nn.MSELoss()\n",
    "for i in range(epoch):\n",
    "    for x, y in data_iter(train_x, train_y.reshape(-1, 1), batch_size):\n",
    "        batch_loss = loss(net(x), y)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch: {} , loss: {}'.format(i, loss(net(x), y)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "piano-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0046, 0.0074]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data  - true_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "controlling-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0060])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].bias.data - true_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-seafood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
